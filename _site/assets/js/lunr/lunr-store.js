var store = [{
        "title": "[Alexnet] ImageNet Classification with Deep Convolutional Neural Networks",
        "excerpt":"Alexnet Architecture   Alexnetì€ 8ê°œì˜ í•™ìŠµê°€ëŠ¥í•œ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ 5ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì™€ 3ê°œì˜ FC ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì—ì„œ ë³´ì—¬ì§€ëŠ” ê²ƒê³¼ ê°™ì´ ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ê·¸ë¦¬ê³  ë‘ ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì‚¬ì´ì—ë§Œ Max-Pooling ê³¼ Local Response Normalization ê°€ ìˆë‹¤.       ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì…ë ¥ ë˜ëŠ” ì´ë¯¸ì§€ëŠ” 224 x 224 x 3 í˜•íƒœì´ì§€ë§Œ, ì´ëŠ” ì˜ëª» í‘œê¸°ëœ ê²ƒì´ë¯€ë¡œ 227 (Height) x 227 (Width) x 3 (Channel) ë¡œ ìˆ˜ì •ë˜ì–´ì•¼ í•œë‹¤.   ì²« ë²ˆì§¸ ë ˆì´ì–´ (ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´)           ì£¼ì–´ì§„ ì…ë ¥ ë°ì´í„° (227 x 227 x 3) ì— ëŒ€í•´ 96ê°œì˜ 11 x 11 x 3 í•„í„° (Filter) ë¡œ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. ì´ ë ˆì´ì–´ì—ì„œëŠ” Stride ì„ 4ë¡œ ì„¤ì •í•˜ê³ , Padding ì€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤.            ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ Filterì˜ í¬ê¸°, Strideì˜ í¬ê¸°, Padding ì—¬ë¶€ì— ë”°ë¼ì„œ Feature Map í¬ê¸°ê°€ ê²°ì •ëœë‹¤. ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì˜ ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ì‚°ì •í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤ (IH = Image Height, IW = Image  Width, FH = Feature Height, FW = Feature Width)   \\[\\bigg( \\frac{IH - FH + 2 \\cdot Padding}{Stride} + 1, \\frac{IW - FW + 2 \\cdot Padding}{Stride} + 1\\bigg)\\]  \\[\\bigg( \\frac{227 - 11 + 2 \\cdot 0}{4}, \\frac{227- 11 + 2 \\cdot 0}{4} \\bigg) = (55,55)\\]           ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì´ ëë‚œ í›„ì˜ ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸° - 55 x 55 x 96            í™œì„±í™” í•¨ìˆ˜ - ReLU &amp; Normalization            ì´ì–´ì„œ 3 x 3 Max-Pooling (Stride = 2) ë ˆì´ì–´ì— ë“¤ì–´ê°€ê²Œ ë˜ë©´ Feature Mapì´ 27 x 27 x 96 ìœ¼ë¡œ ë³€í•œë‹¤. Max-Pooling ë ˆì´ì–´ì˜ ì¶œë ¥ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³µì‹ì„ ì‚¬ìš©í•œë‹¤.   \\[\\bigg( \\bigg \\lfloor \\frac{IH - FH}{Stride} + 1 \\bigg \\rfloor, \\bigg\\lfloor\\frac{IW - FW}{Stride} + 1\\bigg\\rfloor \\bigg)\\]  \\[\\bigg( \\frac{55 - 3}{2} + 1,  \\frac{55 - 3}{2} + 1 \\bigg) = (27, 27)\\]      ë‘ ë²ˆì§¸ ë ˆì´ì–´ (ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´)           ì²« ë²ˆì§¸ ë ˆì´ì–´ ì¶œë ¥ ë°ì´í„° (27 x 27 x 96) ë¥¼ ë‘ ë²ˆì§¸ ë ˆì´ì–´ì—ì„œì˜ ì…ë ¥ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê³ , 256 ê°œì˜ 5 x 5 x 96 í•„í„°ë¥¼ ì‚¬ìš©í•´ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì„ í•œë‹¤. ì´ ë ˆì´ì–´ì—ì„œì˜ Stride ëŠ” 1ì´ê³  Padding ì€ ì´ì „ ë‹¨ê³„ì™€ ë‹¤ë¥´ê²Œ 2ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤.            Convolution ì—°ì‚°ì´ ëë‚œ í›„ì˜ ì¶œë ¥ ë°ì´í„° í¬ê¸° - 27 x 27 x 256            í™œì„±í™” í•¨ìˆ˜ - ReLU &amp; Normalization            ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì™€ ë¹„ìŠ·í•˜ê²Œ, ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì˜ ì¶œë ¥ê°’ì´ 3 x 3 Maxpooling (Stride = 2) ë ˆì´ì–´ì— ë“¤ì–´ê°€ë©´ Feature Mapì˜ í¬ê¸°ëŠ” 13 x 13 x 256 ìœ¼ë¡œ ë³€í•œë‹¤.       ì„¸ ë²ˆì§¸ ë ˆì´ì–´ (ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´)           384 ê°œì˜ 3 x 3 x 256 í•„í„°ë¥¼ ì‚¬ìš©í•´ ì´ì „ ë‹¨ê³„ì—ì„œì˜ Feature Mapì— Convolution ì—°ì‚°ì„ í•´ì¤€ë‹¤.            Stride ê³¼ Padding ë‘˜ ë‹¤ 1 ë¡œ ì„¤ì •í•´ì£¼ë©´, ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸°ëŠ” 13 x 13 x 384 ê°€ ë©ë‹ˆë‹¤.            í™œì„±í™” í•¨ìˆ˜ - ReLU       ë„¤ ë²ˆì§¸ ë ˆì´ì–´ (ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´)      384 ê°œì˜ 3 x 3 x 284 í•„í„°ë¥¼ ì‚¬ìš©í•´ ì´ì „ ë‹¨ê³„ì—ì„œì˜ Feature Mapì— Convolution ì—°ì‚°ì„ í•´ì¤€ë‹¤.   Stride ê³¼ Padding ë‘˜ ë‹¤ 1 ë¡œ ì„¤ì •í•´ì£¼ë©´, ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸°ëŠ” 13 x 13 x 384 ê°€ ë©ë‹ˆë‹¤.   í™œì„±í™” í•¨ìˆ˜ - ReLU   ë‹¤ì„¯ ë²ˆì§¸ ë ˆì´ì–´ (ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´)      384 ê°œì˜ 3 x 3 x 284 í•„í„°ë¥¼ ì‚¬ìš©í•´ ì´ì „ ë‹¨ê³„ì—ì„œì˜ Feature Mapì— Convolution ì—°ì‚°ì„ í•´ì¤€ë‹¤.   Stride ê³¼ Padding ë‘˜ ë‹¤ 1 ë¡œ ì„¤ì •í•´ì£¼ë©´, ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸°ëŠ” 13 x 13 x 384 ê°€ ë©ë‹ˆë‹¤.   í™œì„±í™” í•¨ìˆ˜ - ReLU   ì„¸ ë²ˆì§¸ì™€ ë„¤ ë²ˆì§¸ ë ˆì´ì–´ì™€ ë‹¤ë¥´ê²Œ 3 x 3 Maxpooling (Stride = 2) ì„ í•´ì£¼ë©´ 6 x 6 x 256 íŠ¹ì„±ë§µì´ ë‚˜ì˜¨ë‹¤.   ì—¬ì„¯ ë²ˆì§¸ ë ˆì´ì–´ (FC ë ˆì´ì–´)      ì¥ë‚œê° ë¸”ë¡ìœ¼ë¡œ ë§Œë“  3D ë°•ìŠ¤ Feature Mapì„ ìƒìƒí•´ë³´ì. ì¥ë‚œê° ë¸”ë¡ì„ í•œ ì¤„ë¡œ ë†’ì´ ìŒ“ì•„ ì˜¬ë¦°ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. ë”°ë¼ì„œ 6 x 6 x 256  Feature Map í•œ ì¤„ë¡œ ìŒ“ì•„ ì˜¬ë¦¬ê²Œ ë˜ë©´ ì¤„ (vector) ì˜ ê¸¸ì´ (size)ëŠ” 9216 ê°€ ëœë‹¤.   9216 ì°¨ì›ì˜ ë²¡í„°ë¥¼ 4096 ì°¨ì›ì˜ ë²¡í„°ì™€ ì—°ê²°ì‹œì¼œì¤€ë‹¤.   í™œì„±í™” í•¨ìˆ˜ - ReLU   ì¼ê³± ë²ˆì§¸ ë ˆì´ì–´ (FC ë ˆì´ì–´)      ì´ ë ˆì´ì–´ì—ì„œëŠ” 4096 ì°¨ì›ì˜ ë²¡í„°ë¥¼ ë˜‘ê°™ì€ ì°¨ì›ì˜ ë²¡í„°ì™€ ì—°ê²°ì‹œì¼œì¤€ë‹¤.   í™œì„±í™” í•¨ìˆ˜ - ReLU   ì—¬ëŸ ë²ˆì§¸ ë ˆì´ì–´ (FC ë ˆì´ì–´)      ì´ ë ˆì´ì–´ëŠ” Alexnet êµ¬ì¡°ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ì´ê³ , 4096 ì°¨ì›ì˜ ë²¡í„°ë¥¼ 1000 ì°¨ì› (ë ˆì´ë¸” ë°ì´í„° ì¢…ë¥˜) ë²¡í„°ì— ì—°ê²°ì‹œì¼œì¤€ë‹¤.   í™œì„±í™” í•¨ìˆ˜ - Softmax   Alexnet Tensorflow ì‹¤ìŠµ   Configuration      SGD (Stochastic Gradient Descent)   Batch Size: 128   Momentum: 0.9   Learning Rate: 0.01   Weight Decay: 0.0005   import tensorflow as tf from tensorflow.keras.layers import Conv2D, Dense, Flatten from tensorflow.keras.layers import  BatchNormalization, Dropout, MaxPool2D from tensorflow.keras.models import Sequential from sklearn.model_selection import train_test_split  # í…ì„œí”Œë¡œìš°ì—ì„œ CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ í•™ìŠµë°ì´í„° 50000, í…ŒìŠ¤íŠ¸ ë°ì´í„° 10000 (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()  # CIFAR10 ë ˆì´ë¸” ë°ì´í„° CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # í•™ìŠµë°ì´í„°ì—ì„œ train/validation ë‚˜ëˆ„ê¸° train_images, validation_images, train_labels, validation_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)  # ë°ì´í„° ì¤€ë¹„ train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)) test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)) validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))  IMG_ROWS = 227 IMG_COLS = 227  AUTOTUNE = tf.data.experimental.AUTOTUNE def augment(image,label):     image = tf.image.resize(image, (IMG_ROWS,IMG_COLS)) # CIFAR10 32x32x3 --&gt; 227x227x3      image = tf.image.convert_image_dtype(image, tf.float32)     return image,label  train_ds = (train_ds                 .map(augment)                 .batch(batch_size=32, drop_remainder=True)                 .prefetch(AUTOTUNE)) test_ds=(test_ds                 .map(augment)                 .batch(batch_size=32,drop_remainder=True)) validation_ds = (validation_ds                 .map(augment)                 .batch(batch_size=32, drop_remainder=True))  # í…ì„œí”Œë¡œìš° Alexnet ëª¨ë¸ model = Sequential([     Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(IMG_ROWS,IMG_COLS,3)),     BatchNormalization(),     MaxPool2D(pool_size=(3,3), strides=(2,2)),     Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),     BatchNormalization(),     MaxPool2D(pool_size=(3,3), strides=(2,2)),     Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),     BatchNormalization(),     Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),     BatchNormalization(),     Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),     BatchNormalization(),     MaxPool2D(pool_size=(3,3), strides=(2,2)),     Flatten(),     Dense(4096, activation='relu'),     Dropout(0.5),     Dense(4096, activation='relu'),     Dropout(0.5),     Dense(10, activation='softmax') ])  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=0.00001)  opt = tf.optimizers.SGD(lr=0.01, momentum=0.9) model.compile(loss='sparse_categorical_crossentropy', optimizer= opt, metrics=['accuracy']) model.summary()  model.fit(train_ds, epochs = 50, validation_data = validation_ds, callbacks=[reduce_lr]) model.evaluate(test_ds)   Reference:      https://wikidocs.net/165426   https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html   https://cs231n.github.io/convolutional-networks/  ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/alexnet",
        "teaser": null
      },{
        "title": "[Resnet] Deep Residual Learning for Image Recognition",
        "excerpt":"Resnet   VGG ëª¨ë¸ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œ, ê³¼ì—° ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë§Œìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì„ê¹Œ? ë¼ëŠ” ì˜ë¬¸ì„ ê°€ì§€ê³  ì‹œì‘ëœ ì—°êµ¬ ëª¨ë¸ì´ Resnet ì´ë‹¤. ì•„ë˜ ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” ê²ƒê³¼ ê°™ì´ CNN ë ˆì´ì–´ë¥¼ 20 ê°œì—ì„œ 56 ê°œë¡œ ëŠ˜ë ¸ì„ ë•Œ training ê³¼ test error ëª¨ë‘ ì¢‹ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì™œ ì´ëŸ° í˜„ìƒì´ ìƒê¸°ëŠ” ê²ƒì¼ê¹Œ? ì—­ì „íŒŒí•˜ë‹¤ê°€ ê°€ì¤‘ì¹˜ì— ë”°ë¥¸ ê²°ê³¼ê°’ì˜ ê¸°ìš¸ê¸°ê°€ 0ì— ê°€ê¹Œì›Œì§€ê±°ë‚˜ ë¹„ìƒì ìœ¼ë¡œ ì»¤ì§€ê¸° ë–„ë¬¸ì— í•™ìŠµì´ ì˜ ë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. ì´ ë¬¸ì œë¥¼ gradient vanishing/exploding ì´ë¼ê³  í•œë‹¤. ì´ ì™¸ì—ë„ ë„¤íŠ¸ì›Œí¬ì˜ ë ˆì´ì–´ê°€ ì–´ëŠ ì •ë„ ê¹Šì–´ì§€ë©´ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” degradation ë¬¸ì œë„ ìˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ ë¬¸ì œë¥¼ residual learning ê°œë…ìœ¼ë¡œ í•´ê²°í•˜ê³ ì í–ˆë‹¤.       Residual Block       ê¸°ì¡´ ì‹ ê²½ë§ì€ x ê°’ì´ ì…ë ¥ ë°ì´í„°ë¡œ ë“¤ì–´ ì™”ì„ ë•Œ y ê°’ìœ¼ë¡œ ë§¤í•‘í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ì—ˆë‹¤. í•˜ì§€ë§Œ Resnet ëª¨ë¸ì€ $F(x) + x$ ë¥¼ ìµœì†Œí™” í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ì¦‰, $F(x)$ë¥¼ 0ì— ê°€ê¹ê²Œ ë§Œë“¤ì–´ $H(x) - x$ (ì”ì°¨)ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œ $H(x) = x$ ê°€ ë˜ë„ë¡ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ë‹¤. ì—¬ê¸°ì„œ ì…ë ¥ ë°ì´í„°ì¸ $x$ ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì“°ëŠ” ê²ƒì¸ Skip Connection ì´ë‹¤. Skip Connectionì€ ì…ë ¥ ê°’ì´ ì¸µë“¤ ì‚¬ì´ë¥¼ ê±´ë„ˆë›°ì–´ ì¶œë ¥ì— ë”í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì—­í• ì„ í•œë‹¤.   Residual Architecture           Mini Resnet Tensorflow ì‹¤ìŠµ   import tensorflow as tf from tensorflow.keras.datasets import mnist from tensorflow.keras.layers import Input, Dense, concatenate, Conv2D from tensorflow.keras.layers import BatchNormalization, Flatten, Add, Activation from tensorflow.keras.models import Model  # Identity Block class IdentityBlock(Model):     def __init__(self, filters, kernel_size):         super(IdentityBlock, self).__init__()         self.conv1 = Conv2D(filters, kernel_size, padding='same')         self.bn1 = BatchNormalization()         self.conv2 = Conv2D(filters, kernel_size, padding='same')         self.bn2 = BatchNormalization()         self.relu = Activation('relu')         self.add = Add()          def call(self, inputs):         x = self.conv1(inputs)           x = self.bn1(x)         x = self.relu(x)                    x = self.conv2(x)           x = self.bn2(x)                  x = self.add([x, inputs])         x = self.relu(x)         return x  class ResNet(Model):     def __init__(self, num_classes):         super(ResNet, self).__init__()         self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')         self.bn = tf.keras.layers.BatchNormalization()         self.relu = tf.keras.layers.Activation('relu')         self.max_pool = tf.keras.layers.MaxPool2D((3, 3))         self.id1a = IdentityBlock(64, 3)         self.id1b = IdentityBlock(64, 3)         self.global_pool = tf.keras.layers.GlobalAveragePooling2D()         self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')          def call(self, inputs):         x = self.conv(inputs)         x = self.bn(x)         x = self.relu(x)         x = self.max_pool(x)          x = self.id1a(x)         x = self.id1b(x)          x = self.global_pool(x)         return self.classifier(x)      (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train / 255. x_test = x_test / 255. x_train = x_train[:,:,:,tf.newaxis] x_test = x_test[:,:,:,tf.newaxis]  resnet = ResNet(10) resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) resnet.fit(x_train, y_train, epochs=5) resnet.evaluate(x_test, y_test)    Reference:      https://arxiv.org/abs/1512.03385   https://wikidocs.net/137252   https://cs231n.github.io/convolutional-networks/   https://junstar92.tistory.com/146  ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/resnet",
        "teaser": null
      },{
        "title": "[VGG] Very Deep Convolutional Networks For Large-Scale Image Recognition",
        "excerpt":"VGG Architecture     VGG íŠ¹ì§•      ê¸°ë³¸ì ìœ¼ë¡œ í•„í„° (Filter) ì‚¬ì´ì¦ˆëŠ” 3 x 3 ìœ¼ë¡œ ì„¤ì •í–ˆê³ , VGG-16 ì´í›„ ëª¨ë¸ì€ í•„í„° 1 x 1 ë„ í•¨ê»˜ ì‚¬ìš©í–ˆë‹¤.   í•„í„° 3 x 3 ë¥¼ ì‚¬ìš©í•˜ë©´, ë” í° ì‚¬ì´ì¦ˆì˜ í•„í„°ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ë³´ë‹¤ (ex. 7 x 7) ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ì¸µì„ ìŒ“ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒê³¼ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.            ë‘ ê°œì˜ 3 x 3 í•„í„°ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì€ í•œ ê°œì˜ 5 x 5 í•„í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ Effective Receptive Fieldë¥¼ ê°€ì§€ê³  ìˆë‹¤. ë”°ë¼ì„œ ë” ê¹Šì´ ìŒ“ìœ¼ë©´ì„œ ëª¨ë¸ì˜ ë¹„ì„ í˜•ì„±ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆë‹¤.       3 ê°œì˜ 3 x 3 í•„í„°ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ 3 * (3 * 3 * $Channel_{prev}$  + 1) * $Channel_{curr}$ &lt; 1 ê°œì˜ 7 x 7 í•„í„°ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ 1 * (7 * 7 * $Channel_{prev}$ + 1) * $Channel_{curr}$           í•„í„° 1 x 1 ì˜ ì‚¬ìš© ì´ì : ì°¨ì› ì¶•ì†Œ, ë¹„ì„ í˜•ì„±ì˜ ì¦ê°€, ê·¸ë¦¬ê³  ê³„ì‚°ëŸ‰ ê°ì†Œ            ì˜ˆë¥¼ ë“¤ì–´, 12 x 12 x 3 ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ 5ê°œì˜ 3 x 3 í•„í„°ë¥¼ ì ìš©í•˜ë©´ ìµœì¢… íŒŒë¼ë¯¸í„°ì˜ ê³„ì‚°ëŸ‰ì€ 12 * 12 * 3 * 3 * 3 * 5 = 19440 ë²ˆì´ì§€ë§Œ, 1 ê°œì˜ 1 x 1 ì ìš©í•˜ê³  5ê°œì˜ 3 x 3 í•„í„°ë¥¼ ì ìš©í•˜ë©´  12 * 12 * 3  + 12 * 12 * 1 * 5 * 3 * 3 = 6912 ë²ˆì˜ ê³„ì‚°ëŸ‰ìœ¼ë¡œ ì¤„ì–´ë“ ë‹¤.           VGG-16 Tensorflow ì‹¤ìŠµ   Configuration           Mini-batch Gradient Descent            Batch Size: 256            Momentum: 0.9            Learning Rate: 0.01            Weight Decay:  $L_{2}$ multiplier set to $5 Â· 10^{âˆ’4}$       import tensorflow as tf from tensorflow.keras.layers import Input, Dense, Conv2D from tensorflow.keras.layers import Flatten, MaxPooling2D from tensorflow.keras.optimizers import Adam, RMSprop from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping from tensorflow.keras.models import Model, Sequential  from tensorflow.keras.datasets import cifar10 from sklearn.model_selection import train_test_split  import tensorflow_addons as tfa  (train_images, train_labels), (test_images, test_labels) = cifar10.load_data() train_images, validation_images, train_labels, validation_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)  # ë°ì´í„° ì¤€ë¹„ train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)) test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)) validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))  IMG_ROWS = 224 IMG_COLS = 224  AUTOTUNE = tf.data.experimental.AUTOTUNE def augment(image,label):     image = tf.image.resize(image, (IMG_ROWS,IMG_COLS)) # CIFAR10 32x32x3 --&gt; 227x227x3      image = tf.image.convert_image_dtype(image, tf.float32)     return image,label  train_ds = (train_ds                 .map(augment)                 .batch(batch_size=32, drop_remainder=True)                 .prefetch(AUTOTUNE)) test_ds=(test_ds                 .map(augment)                 .batch(batch_size=32,drop_remainder=True)) validation_ds = (validation_ds                 .map(augment)                 .batch(batch_size=32, drop_remainder=True))   model = Sequential() model.add(Conv2D(input_shape = (IMG_ROWS, IMG_COLS, 3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))  model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))  model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 256, kernel_size = (1,1), padding = \"same\", activation = \"relu\")) model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))  model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 512, kernel_size = (1,1), padding = \"same\", activation = \"relu\")) model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))  model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\")) model.add(Conv2D(filters = 512, kernel_size = (1,1), padding = \"same\", activation = \"relu\")) model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))  model.add(Flatten()) model.add(Dense(units = 4096, activation = \"relu\")) model.add(Dense(units = 4096, activation = \"relu\")) model.add(Dense(units = 10, activation = \"softmax\"))  opt = tfa.optimizers.SGDW(weight_decay=0.0005, learning_rate=0.01, momentum=0.9) model.compile(optimizer = opt, loss= 'sparse_categorical_crossentropy', metrics = ['accuracy']) reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=0.00001) model.fit(train_ds,             epochs = 50,             validation_data = validation_ds,             callbacks = [reduce_lr]) model.evaluate(test_ds)   Reference:      https://wikidocs.net/165427   Stanford CS231n   https://ai.plainenglish.io/vggnet-with-tensorflow-transfer-learning-with-vgg16-included-7e5f6fa9479a   https://arxiv.org/abs/1409.1556  ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/vgg",
        "teaser": null
      },{
        "title": "[GoogLeNet] Going Deeper with Convolutions",
        "excerpt":"GoogLeNet   CNN ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ê°€ì¥ ì§ì ‘ì ì¸ ë°©ë²•ì´ ë„¤íŠ¸ì›Œí¬ì˜ ê¹Šì´ë¥¼ ëŠ˜ë¦¬ëŠ” ë°©ë²•ì´ë‹¤. í•˜ì§€ë§Œ ë„¤íŠ¸ì›Œí¬ê°€ ê¹Šì–´ì§€ë©´ íŒŒë¼ë¯¸í„° ìˆ˜ì™€ ì—°ì‚°ëŸ‰ì´ ë§ì•„ì§€ê³  overfitting ë¬¸ì œì— ë…¸ì¶œë  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Szegedt et al. ì€ ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì¡°ì  ë³€í™”ê°€ í•„ìš”í•˜ë‹¤ê³  ìƒê°í–ˆê³ , Inception ëª¨ë“ˆë¡œ êµ¬ì„±ëœ GoogLeNetìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í–ˆë‹¤.   GoogLeNet Architecture       GoogLeNetì€ 22 ë ˆì´ì–´ ì¸µìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ì´ 3ê°œì˜ íŠ¹ì§•ì´ ìˆë‹¤      1 x 1 Filter Conv   Inception Module   Auxiliary Classifier   1 x 1 Filter Conv   1 x 1 í•„í„°ëŠ” ì°¨ì› ì¶•ì†Œ, ë¹„ì„ í˜•ì„±ì˜ ì¦ê°€, ê·¸ë¦¬ê³  ê³„ì‚°ëŸ‰ ê°ì†Œë¥¼ ì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. GoogLeNetì—ì„œ 1 x 1 í•„í„°ë¥¼ Feature Map ì°¨ì›ì˜ ê°œìˆ˜ë¥¼ ì¤„ì´ëŠ” ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 11 x 11 x 300 Feature Mapì´ ìˆë‹¤ê³  ê°€ì •í•´ë³´ì. Feature Mapì— 30ê°œì˜ 5 x 5 í•„í„°ë¡œ Convolutionì„ ì ìš©í•˜ë©´ 11 x 11 x 30 Feature Mapì´ ìƒì„±ëœë‹¤ (Stride = 1, Padding = 0). ì´ë•Œ í•„ìš”í•œ ì—°ì‚°ëŸ‰ì€ 11 x 11 x 30 x 5 x 5 x 300 = 27225000 ì´ ëœë‹¤.   ì´ë²ˆì—ëŠ” 11 x 11 x 300 Feature Mapì— ë¨¼ì € 5ê°œì˜ 1 x 1 í•„í„°ë¥¼ ì ìš©í•œ ë’¤, 30ê°œì˜ 5 x 5 í•„í„°ë¥¼ ì ìš©í•´ë³´ì. ê·¸ëŸ¬ë©´  11 x 11 x 5 Feature Mapì´ ìƒì„±ë˜ê³ , ì´ Feature Mapì— 5 x 5 í•„í„°ë¥¼ ì ìš©í•´ì£¼ë©´ ì‚¬ì´ì¦ˆê°€ 11 x 11 x 30ì¸ Feature Mapì´ ìƒì„±ëœë‹¤. ê·¸ëŸ¬ë©´ ì—°ì‚°ëŸ‰ì€ ì–¼ë§ˆì¼ê¹Œ? 1 x 1 í•„í„°ë¥¼ ì ìš©í–ˆì„ ë•Œì˜ ì—°ì‚°ëŸ‰ì€ 11 * 11 * 300 * 1 * 1 * 5 = 181500ì´ê³ , 5 x 5 í•„í„°ë¥¼ ì ìš©í–ˆì„ ë•Œì˜ ì—°ì‚°ëŸ‰ì€ 11 * 11 * 5 * 5 * 5 * 30 = 21780 ì´ë‹¤. ë”°ë¼ì„œ ì´ ì—°ì‚°ëŸ‰ì€ 181500 + 21780 = 203280 ì´ë‹¤. 1 x 1 í•„í„°ë¥¼ ì¤‘ê°„ì— ì‚¬ìš©í–ˆì„ ë•Œ  ë” ì ì€ ì—°ì‚°ëŸ‰ì„ ê°€ì§ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì—°ì‚°ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤ëŠ” ì ì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ë” ê¹Šì´ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë„ì™€ì¤€ë‹¤ëŠ” ì ì—ì„œ ì¤‘ìš”í•˜ë‹¤.   Inception Module     GoogLeNetì€ ì´ 9ê°œì˜ Inception Module ì„ ì‚¬ìš©í•˜ê³  ìˆë‹¤. GoogLeNetì—ì„œ ì‚¬ìš©ëœ ëª¨ë“ˆì€ 1x1 Convê°€ í¬í•¨ëœ (b) ëª¨ë¸ì´ë‹¤. ìœ„ì—ì„œ ì„¤ëª…í–ˆë“¯ì´ 1x1 í•„í„°ë¡œ Conv í•˜ë©´ Feature Map ì˜ ì°¨ì›ì˜ ê°œìˆ˜ë¥¼ ì¤„ì—¬ì¤„ ìˆ˜ ìˆë‹¤. 1x1 í•„í„°ë¥¼ ì œì™¸í•œ ë²„ì „ì„ ì‚´í´ë³´ë©´, ì´ì „ ì¸µì—ì„œ ìƒì„±ëœ Feature Mapì„ 1x1 í•„í„°, 3x3 í•„í„°, 5x5 í•„í„°, 3x3 Max Pooling ê²°ê³¼ ì–»ì€ Feature Mapë“¤ì„ ëª¨ë‘ í•¨ê»˜ ìŒ“ì•„ì¤€ë‹¤.   Auxiliary Classifier   ì‹ ê²½ë§ì˜ ê¹Šì´ê°€ ê¹Šì–´ì§ˆ ìˆ˜ë¡ vanishing gradient ë¬¸ì œê°€ ë°œìƒí•œë‹¤. Vanishing Gradient ë¬¸ì œë€ back propagation í•˜ëŠ” ê³¼ì •ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´í„°í•˜ë©´ì„œ gradientê°€ ì ì  ì‘ì•„ì ¸ì„œ 0ì´ ë˜ì–´ë²„ë¦° ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ ì‹ ê²½ë§ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.   Auxiliary classifierëŠ” í•™ìŠµì‹œì—ë§Œ ì‚¬ìš©í•˜ê³  inference í•  ë•Œ GoogLeNet ì¤‘ê°„ì— ìˆëŠ” 2ê°œì˜ auxiliary classifierë¥¼ ëª¨ë‘ ì œê±°í•´ì•¼ í•œë‹¤.   GooLeNet Tensorflow ì‹¤ìŠµ   import tensorflow as tf from tensorflow.keras.datasets import mnist from tensorflow.keras import layers, Sequential, Model  class Inception(layers.Layer):     def __init__(self, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj):         super(Inception, self).__init__()          self.b1 = Sequential([             layers.Conv2D(n1x1, (1, 1)),             layers.BatchNormalization(),             layers.ReLU()         ])         self.b2 = Sequential([             layers.Conv2D(n3x3_reduce, (1, 1)),             layers.BatchNormalization(),             layers.ReLU(),             layers.Conv2D(n3x3, (3, 3), padding='same'),             layers.BatchNormalization(),             layers.ReLU()         ])         self.b3 = Sequential([             layers.Conv2D(n5x5_reduce, (1, 1)),             layers.BatchNormalization(),             layers.ReLU(),             layers.Conv2D(n5x5, (3, 3), padding='same'),             layers.BatchNormalization(),             layers.ReLU(),             layers.Conv2D(n5x5, (3, 3), padding='same'),             layers.BatchNormalization(),             layers.ReLU(),         ])         self.b4 = Sequential([             layers.MaxPool2D((3, 3), 1, padding='same'),             layers.Conv2D(pool_proj, (1, 1)),             layers.BatchNormalization(),             layers.ReLU(),         ])      def call(self, x):         x = tf.concat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], axis=3)         return x   class GoogleNet(Model):     def __init__(self, num_classes, input_shape=(28, 28, 1)):         super(GoogleNet, self).__init__()         self.layer1 = Sequential([             layers.Input(input_shape),             layers.Conv2D(192, (3, 3), padding='same'),             layers.BatchNormalization(),             layers.ReLU()         ])         self.layer2 = Sequential([             Inception(64, 96, 128, 16, 32, 32),             Inception(128, 128, 192, 32, 96, 64),             layers.MaxPool2D((3, 3), 2, padding='same'),         ])         self.layer3 = Sequential([             Inception(192, 96, 208, 16, 48, 64),             Inception(160, 112, 224, 24, 64, 64),             Inception(128, 128, 256, 24, 64, 64),             Inception(112, 144, 288, 32, 64, 64),             Inception(256, 160, 320, 32, 128, 128),             layers.MaxPool2D((3, 3), 2, padding='same'),         ])         self.layer4 = Sequential([             Inception(256, 160, 320, 32, 128, 128),             Inception(384, 192, 384, 48, 128, 128)         ])         self.layer5 = Sequential([             layers.GlobalAveragePooling2D(),             layers.Dropout(0.4),         ])         self.fc = layers.Dense(num_classes, activation='softmax')      def call(self, inputs, training=False):         x = self.layer1(inputs, training=training)         x = self.layer2(x, training=training)         x = self.layer3(x, training=training)         x = self.layer4(x, training=training)         x = self.layer5(x, training=training)         x = tf.reshape(x, (x.shape[0], -1))         x = self.fc(x)         return x      (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train / 255. x_test = x_test / 255. x_train = x_train[:,:,:,tf.newaxis] x_test = x_test[:,:,:,tf.newaxis] # print(x_train.shape) model = GoogleNet(10) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test)    Reference:      https://github.com/marload/ConvNets-TensorFlow2/blob/master/models/GoogLeNet.py   https://bskyvision.com/   https://arxiv.org/abs/1409.4842  ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/googlenet",
        "teaser": null
      },{
        "title": "[Seq2Seq] Sequence to Sequence Learning with Neural Networks",
        "excerpt":"Introduction   ë”¥ëŸ¬ë‹ ê¸°ìˆ ì´ ìŒì„±ì¸ì‹, ê¸°ê³„ë²ˆì—­ ë“±ì˜ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆëŠ” ì‹¤ë§ˆë¦¬ë¥¼ ì œê³µí•˜ê³  ìˆì§€ë§Œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ì˜ ê¸¸ì´ê°€ ê³ ì •ë˜ì–´ì•¼ í•œë‹¤ëŠ” í•œê³„ê°€ ìˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” LSTM ê¸°ë°˜ì˜ Encoder-Decoder ëª¨ë¸ì— ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ ë°ì´í„°ë¥¼ ë„£ì–´ì£¼ê³ , ê°€ë³€ ê¸¸ì´ì˜ ì¶œë ¥ ë°ì´í„°ë¥¼ ìƒì„±í•´ ë²ˆì—­ ë¬¸ì œë¥¼ í’€ê³ ì í–ˆë‹¤.     Seq2Seq   LSTMì˜ ëª©í‘œëŠ” ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì¶œë ¥ ë°ì´í„°ì— ëŒ€í•œ ì¡°ê±´ë¶€ í™•ë¥ ì„ ì•„ë˜ ì‹ê³¼ ê°™ì´ í‰ê°€í•˜ëŠ” ê²ƒì´ë‹¤. LSTMì€ ìš°ì„  ì…ë ¥ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ê³ ì •ëœ ì°¨ì›ì˜ context vectorë¥¼ ì—°ì‚°í•˜ê³ , ì•„ë˜ ìˆ˜ì‹ìœ¼ë¡œ ì—°ì‚°ë˜ëŠ” í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. ì´ë•Œ $p(y_{t}|v,y_1,y_2,â€¦,y_{t-1})$  ë¶„í¬ëŠ” ë‹¨ì–´ì— ëŒ€í•œ softmaxì— í•´ë‹¹ëœë‹¤.   \\[p(y_1,...,y_{T^{'}}| x_{1}, ..., x_{T}) = \\prod p(y_t|v, y_{1}, ...,y_{t-1})\\]    ì•ì„œ ì–¸ê¸‰í–ˆë‹¤ì‹œí”¼ Seq2Seqì€ ì…ë ¥ ë°ì´í„°ë¥¼ ìœ„í•œ Encoderì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ìœ„í•œ Decoderë¥¼ ì‚¬ìš©í•œë‹¤. EncoderëŠ” ì…ë ¥ ë°ì´í„°ì˜ ë‹¨ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ì•„ì„œ context vector ë§Œë“ ë‹¤. ì…ë ¥ ë°ì´í„°ì˜ ì •ë³´ê°€ context vectorë¡œ ëª¨ë‘ ì••ì¶•ë˜ë©´ EncoderëŠ” context vectorë¥¼ Decoderë¡œ ë„£ì–´ì£¼ê³ , DecoderëŠ” ë²ˆì—­ëœ ë‹¨ì–´ë¥¼ í•œ ê°œì”© ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥í•˜ê²Œ ëœë‹¤.   ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì—­ìˆœìœ¼ë¡œ ë°°ì¹˜í•œ í›„ ëª¨ë¸ì— ë„£ì–´ì¤¬ë‹¤. ì…ë ¥ ë¬¸ì¥ ë°ì´í„°ì˜ ì‹œì‘ì ê³¼ ì¶œë ¥ ë¬¸ì¥ ë°ì´í„°ì˜ ì‹œì‘ì ì´ ë©€ê¸° ë•Œë¬¸ì— ì…ë ¥ ë°ì´í„°ë¥¼ ê±°ê¾¸ë¡œ ë„£ì–´ì¤Œìœ¼ë¡œì¨ minimal time lag íš¨ê³¼ë¥¼ ì ˆê°í–ˆë‹¤.   Experiment           ë°ì´í„°ì…‹: WMT 14 English to French ë°ì´í„°ì¤‘ ì¼ë¶€ ì„ íƒí•´ ì‚¬ìš©í–ˆìœ¼ë©°, ì¼ë°˜ì ì¸ neural language modelì€ ê° ë‹¨ì–´ì˜ ë²¡í„° í‘œí˜„ì— ì˜ì¡´ì ì´ê¸° ë•Œë¬¸ì— ë‘ ì–¸ì–´ì— ëŒ€í•´ ê³ ì •ëœ í¬ê¸°ì˜ ë‹¨ì–´ ì‚¬ì „ì„ ì‚¬ìš©í–ˆë‹¤. ë‹¨ì–´ ì‚¬ì „ì— ì—†ëŠ” ëª¨ë“  out-of-vocabulary wordëŠ” UNK í† í°ìœ¼ë¡œ ì²˜ë¦¬í–ˆë‹¤.            ëª¨ë¸ ê°€ì¤‘ì¹˜: -0.08 ~ 0.08 uniform distribution            SGD without momentum (learning rate=0.7, epoch 5 ì´í›„ ë§¤ epoch ë§ˆë‹¤ lr ì ˆë°˜ìœ¼ë¡œ ë§Œë“¦)            4ê°œì˜ LSTM ë ˆì´ì–´ ì‚¬ìš©               Encoder-Decoder Tensorflow ì‹¤ìŠµ   https://wikidocs.net/24996   Reference:      https://arxiv.org/abs/1409.3215   https://wikidocs.net/24996   https://coshin.tistory.com/47   ","categories": ["Deep Learning"],
        "tags": ["Natural Language Processing"],
        "url": "/deeplearning/seq2seq",
        "teaser": null
      },{
        "title": "[NMF] Non-negative Matrix Factorization",
        "excerpt":"Introduction  NMF (Non-negative matrix factorization)ëŠ” negative value (ë°ì´í„°)ë¥¼ í¬í•¨í•˜ì§€ ì•Šì€ í–‰ë ¬ $V$ë¥¼ negative valueë¥¼ í¬í•¨í•˜ì§€ ì•Šì€ í–‰ë ¬ $W$ (ê°€ì¤‘ì¹˜ í–‰ë ¬)ì™€ $H$(íŠ¹ì„± í–‰ë ¬)ì˜ ê³±ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ê³  ì»´í“¨í„°ë¹„ì „, ì¶”ì²œ ì‹œìŠ¤í…œ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì“°ì¸ë‹¤. NFM ì•Œê³ ë¦¬ì¦˜ì´ ë‹¤ë¥¸ ì°¨ì› ì¶•ì†Œ ì•Œê³ ë¦¬ì¦˜ê³¼ ë‹¤ë¥¸ ì ì€ ë°ì´í„°ì˜ íŠ¹ì„±ì¸ non-negativityë¥¼ ë³´ì¥ ë°›ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.   \\[\\mathbf{V} = W \\times H\\]  NMF ì•Œê³ ë¦¬ì¦˜ ì‹¤ìŠµ   ë‹¤ìŒì€ ì–¼êµ´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì§„í–‰í•œ NMF (components = 3) ì˜ˆì‹œì´ë‹¤.  # ì°¸ê³ : https://jhryu1208.github.io/data/2020/12/10/ML_NMF/ import numpy as np from sklearn.decomposition import NMF from sklearn.datasets import fetch_lfw_people from sklearn.model_selection import train_test_split  people = fetch_lfw_people(min_faces_per_person=20, resize=0.7) image_shape = people.images[0].shape  mask = np.zeros(people.target.shape, dtype=np.bool) for target in np.unique(people.target):     mask[np.where(people.target == target)[0][:50]] = 1      X_people = people.data[mask] y_people = people.target[mask]  X_people = X_people / 255.0  X_train, X_test, y_train, y_test = train_test_split(X_people,y_people, stratify=y_people, random_state=0)   nmf = NMF(n_components=3, random_state=0, max_iter=1000, tol=1e-3) nmf.fit(X_train) X_train_nmf = nmf.transform(X_train) X_test_nmf = nmf.transform(X_test)  fig, axes = plt.subplots(3, 5, figsize=(15, 12),                          subplot_kw={'xticks': (), 'yticks': ()}) for i, (component, ax) in enumerate(zip(nmf.components_, axes.ravel())):     ax.imshow(component.reshape(image_shape))     ax.set_title(\"component {}\".format(i))  ","categories": ["Machine Learning"],
        "tags": ["Recommender System"],
        "url": "/machinelearning/nmf",
        "teaser": null
      },{
        "title": "[Buy It Again] Modeling Repeat Purchase Recommendations",
        "excerpt":"Current Problem   ì´ì»¤ë¨¸ìŠ¤ ê¸°ì—…ì´ ì‚¬ìš©í•˜ëŠ” ì¶”ì²œ ê¸°ëŠ¥ì€ ëŒ€ë¶€ë¶„ ì–´ë–¤ ìƒí’ˆì„ ì¶”ì²œí•  ê²ƒì¸ê°€ì—ë§Œ ë§ì¶”ì–´ì ¸ ìˆë‹¤. ì´ì— ë°˜í•´ ê³ ê°ì´ í•œ ë²ˆ ì´ìƒ êµ¬ë§¤í•œ ìƒí’ˆì„ ì–¸ì œ ì¶”ì²œí•´ì•¼ í•˜ëŠ” ê²ƒì¸ì§€ì— ëŒ€í•œ ì—°êµ¬ê°€ í™œë°œíˆ ì´ë£¨ì–´ì§€ì§€ ëª»í•˜ê³  ìƒíƒœì´ë‹¤. íŠ¹íˆ ìƒí™œìš©í’ˆê³¼ ê°™ì´ ë°˜ë³µì ìœ¼ë¡œ êµ¬ë§¤ê°€ ì¼ì–´ë‚˜ëŠ” ìƒí’ˆì˜ ê²½ìš°, ì¬êµ¬ë§¤ ì‹œê¸°ë¥¼ ì ì ˆíˆ ì˜ˆìƒí•˜ì—¬ ìƒí’ˆì„ ì¶”ì²œí•´ì¤€ë‹¤ë©´ â€˜ë³´ë‹¤ ë” í¸ë¦¬í•œâ€™ â€˜ë” ë‚˜ì€â€™ ê³ ê° ê²½í—˜ì„ ì œê³µí•´ì¤„ ìˆ˜ ìˆë‹¤.   ì•„ë§ˆì¡´ì—ì„œ ë°œí‘œí•œ Repeat Purchase Recommendations ì€ ê³ ê°ì˜ ê³¼ê±° êµ¬ë§¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì´ í•„ìš”í•œ ìƒí’ˆì„ ë‹¤ì‹œ ì¶”ì²œí•´ì£¼ëŠ” ê¸°ëŠ¥ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 1ê°œì›” ì „ ì•„ë§ˆì¡´ ì–´í”Œì—ì„œ í©ì‹œ (210ml x 30ìº”) ì„ êµ¬ë§¤í•œ ì´ë ¥ì´ ìˆëŠ” ê³ ê°ì—ê²Œ ìƒí’ˆì„ ì‹œê¸°ì ì ˆí•˜ê²Œ ì¶”ì²œí•´ì£¼ëŠ” ê¸°ëŠ¥ì´ë‹¤.   Purchase Probability Density (PPD)   PPD ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆë‹¤ \\(P_{A_i}(t_{k+1}=t| t_{1}, t_{2}, t_{3}, â€¦, t_{k})\\)   ê³ ê°ì˜ êµ¬ë§¤ì´ë ¥ ì •ë³´ë¥¼ ê°€ì§€ê³  ê³ ê°ì˜ ì œí’ˆ ì¬êµ¬ë§¤ í™•ë¥ ì„ ê³„ì‚°í•˜ê³  ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒí’ˆì„ ì¶”ì²œê¹Œì§€ í•´ì¤€ë‹¤. Bhagat et al. 2018 ë…¼ë¬¸ì—ì„œëŠ” RCP (Repeat Customer Probability), ATD (Aggregate Time Distribution), PG (Poisson-Gamma), MPG (Modified Poisson-Gamma) ì´ 4ê°œì˜ ëª¨í˜•ì„ ì‚¬ìš©í•´ $P_{A_i} (â‹…)$ êµ¬í•˜ê³ ì í–ˆë‹¤   Assumption1: ì„œë¡œ ë‹¤ë¥¸ ì œí’ˆì„ êµ¬ë§¤í•  ì‚¬ê±´ì€ ë…ë¦½ì´ë‹¤   Assumption2:  \\(P_{A_i} (t_{k+1}=t\\ | \\ t_1, t_2, t_3, â€¦, t_k)â‰ˆQ(A_i)\\cdot R_{A_i} (t_{k+1}| t_1, .., t_k)\\)   $Q(A_i)$: ê³ ê°ì´ ì œí’ˆì„ êµ¬ë§¤í•œ íšŸìˆ˜ê°€ k ì¸ ê²½ìš° (k+1) ë²ˆì§¸ë¡œ ì œí’ˆì„ êµ¬ë§¤í•  ì¬êµ¬ë§¤ í™•ë¥    $R_{A_i}$: ê³ ê°ì´ ì œí’ˆì„ ì¬êµ¬ë§¤í•  ë•Œì˜ $t_{k+1}$ ë¶„í¬   1. Repeat Customer Probability (RCP)   \\[ğ‘…ğ¶ğ‘ƒ_{ğ´_ğ‘–}= \\frac{\\# \\ customers \\ who \\ bought \\  product \\ ğ´_ğ‘– \\ more \\ than \\ once}{\\# \\ customers \\ who \\ bought \\  product \\ ğ´_ğ‘– \\ at \\ least \\ once}\\]  ì œí’ˆ $A_i$ ì„ êµ¬ë§¤í•œ ê³ ê°ì˜ ìˆ˜ë¥¼ í™œìš©í•œ ë² ì´ìŠ¤ë¼ì¸ í™•ë¥  ëª¨ë¸ (Time-Independent)   Assumption:  \\(P_{A_i} (t_{k+1}=t\\ | \\ t_1, t_2, t_3, â€¦, t_k)â‰ˆQ(A_i)â‰ˆRCP_{A_i}\\)   ì—¬ê¸°ì„œ $R_{A_i}(\\cdot)$ ì€ ê³ ì •ëœ r ê°’ ì´ë¼ê³  ê°€ì •í•œë‹¤.   ì„ê³„ê°’ì„ ì‚¬ìš©í•´ ì¶”ì²œ ëª¨ë¸ì˜ í’ˆì§ˆ í–¥ìƒ: $RCP_{A_i}$ &gt; Threshold   Limitation: ê³ ê°ì´ ë°©ê¸ˆ ì „ì— êµ¬ë§¤í•œ ì œí’ˆì´ ì—¬ì „íˆ ì¶”ì²œ ì œí’ˆ ìš°ì„  ìˆœìœ„ì— ì˜¬ë¼ê°€ ìˆì„ ìˆ˜ ìˆìŒ   2. Aggregate Time Distribution (ATD) ëª¨ë¸   \\[ğ‘…_{ğ´_ğ‘–} (ğ‘¡)=lnâ¡â„•(ğ‘¡;\\mu_{i}, \\sigma_{i})=\\frac{1}{\\sqrt{2ğœ‹}  ğ‘¡\\cdot\\sigma_{i}}â‹…expâ¡\\bigg[-\\frac{(lnt - \\mu_i)^2}{2\\sigma_i^2} \\bigg], ğ‘¡&gt;0\\]  ì œí’ˆ $A_i$ë¥¼ ì¬êµ¬ë§¤ê¹Œì§€ ì†Œìš”ëœ ê¸°ê°„ì´ ë¡œê·¸ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ ê²ƒì„ ì‹¤í—˜ì ìœ¼ë¡œ í™•ì¸í–ˆë‹¤. ë¡œê·¸ ì •ê·œ ë¶„í¬ëŠ” Positively Right Skewed í•œ ë¶„í¬ì´ê¸° ë•Œë¬¸ì— í•­ìƒ ì–‘ìˆ˜ê°’ë§Œì„ ê°€ì§„ë‹¤. ë”°ë¼ì„œ ìŒìˆ˜ê°’ì„ ê°€ì§ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ë¬¸ì œì— ëŒ€í•œ ëŒ€ì•ˆì´ ë  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìƒí’ˆì„ ì¬êµ¬ë§¤ê¹Œì§€ì˜ ê°„ê²©, ì²« êµ¬ë§¤ ì†Œìš” ì‹œê°„, êµ¬ë§¤ ê°€ê²©ëŒ€ ë“±ì€ ì „ë¶€ ì–‘ìˆ˜ ê°’ë§Œ ê°–ëŠ”ë‹¤.   ë¡œê·¸ ì •ê·œ ë¶„í¬ë¥¼ ì‚¬ìš©í•´ ì–´ë–¤ ì‚¬ê±´ì˜ ë°œìƒí•˜ëŠ” ì •ë„ê°€ ê¸‰ê²©íˆ ì¦ê°€í–ˆë‹¤ê°€ ë‚®ì•„ì§€ëŠ” ê²ƒì„ ëª¨ë¸í™” ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¬¼ê±´ì„ êµ¬ì…í•˜ê±°ë‚˜ ì´ì‚¬ë¥¼ ê°€ê±°ë‚˜ í•˜ëŠ” ì‚¬ê±´ì€ í•œ ë²ˆ ë°œìƒí•˜ê³  ë‚˜ë©´ ë°œìƒ í™•ë¥ ì´ ê¸‰ê²©ì´ ë‚®ì•„ì§€ëŠ” ì‚¬ê±´ì„ ëª¨ë¸í™” í•  ìˆ˜ ìˆë‹¤.   ì£¼ì–´ì§„ ë°ì´í„°ê°€ ë¡œê·¸ ì •ê·œ ë¶„í¬ë¥¼ ê°€ì •í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ MLEë¡œ ëª¨ìˆ˜ë¥¼ êµ¬í–ˆë‹¤. ë¡œê·¸ ì •ê·œ ë¶„í¬ì˜ ëª¨ìˆ˜ $\\mu_i$ ì™€ $\\sigma_i$ ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤   \\[Likelihood \\ LN \\frac{1}{(2\\pi)^{\\frac{n}{2}} \\cdot (\\sigma_i^2)^{\\frac{n}{2}}} \\cdot \\prod \\bigg(\\frac{1}{t_z} \\bigg) \\cdot exp \\bigg(-\\frac{1}{2\\sigma^2_i} \\sum ln(t_z - \\mu_i)^2 \\bigg)\\]  \\[Likelihood \\ LLN = -\\frac{ğ‘›}{2}lnâ¡(2\\pi)âˆ’\\frac{ğ‘›}{2}lnâ¡(\\sigma_i^2)âˆ’\\frac{1}{2\\sigma_i^2}\\sum ln(t_z - \\mu_i)^2 - \\sum ln(t_z)\\]  \\[\\hat{\\mu_{mle}} = \\frac{1}{n}\\sum ln(t_z), \\ \\hat{\\sigma_{mle}^2} = \\frac{1}{n} \\sum (lnt - \\mu_i)^2\\]  ê·¸ë¦¬ê³  ë…¼ë¬¸ì—ì„œëŠ” ë°ì´í„°ë¥¼ theoretical ë¡œê·¸ì •ê·œë¶„í¬ì™€ ë¹„êµí•˜ê¸° ìœ„í•´ qqplotì„ ì‚¬ìš©í–ˆë‹¤.        ê·¸ë˜í”„ ì™¼ìª½ ì•„ë˜, ì ë“¤ì´ ì„  ìœ„ - ë°ì´í„° ë¶„í¬ì˜ ì™¼ìª½ ê¼¬ë¦¬ê°€ ë¡œê·¸ì •ê·œë¶„í¬ì˜ ê²ƒë³´ë‹¤ ì§§ë‹¤.   ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ìœ„, ì ë“¤ì´ ì„  ì•„ë˜ - ë°ì´í„° ë¶„í¬ì˜ ì˜¤ë¥¸ìª½ ê¼¬ë¦¬ê°€ ë¡œê·¸ì •ê·œë¶„í¬ì˜ ê²ƒë³´ë‹¤ ì§§ë‹¤.   Assumption:  \\(P_{A_i} (t_{k+1}=t\\ | \\ t_1, t_2, t_3, â€¦, t_k)â‰ˆR_{A_i}(t)\\)   ì—¬ê¸°ì„œ $Q_{A_i}(\\cdot)$ ì€ ê³ ì •ëœ q ê°’ ì´ë¼ê³  ê°€ì •í•œë‹¤.   ì„ê³„ê°’ì„ ì‚¬ìš©í•´ ì¶”ì²œ ëª¨ë¸ì˜ í’ˆì§ˆ í–¥ìƒ: $R_{A_i}(t)$ &gt; Threshold   Limitation: ì‚¬ëŒë§ˆë‹¤ ì œí’ˆì„ ì‚¬ìš©í•˜ëŠ” ì†ë„ëŠ” ì „ë¶€ ë‹¤ ë‹¤ë¦„. ì–´ë–¤ ì‚¬ëŒì€ ê°íœ´ì§€ í™”ì¥ì§€ 20ë§¤ë¥¼ 3ì£¼ ë§Œì— ì‚¬ìš©í•˜ê³  ì–´ë–¤ ê³ ê°ì€ ë™ì¼ ì œí’ˆì„ 1ì£¼ì¼ë§Œì— ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‚¬ëŒì— ë”°ë¼ ì œí’ˆ êµ¬ë§¤ ì£¼ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.   3. Poisson-Gamma Mixture (PG) ëª¨ë¸   í¬ì•„ì†¡ ë¶„í¬ì™€ ê°ë§ˆ ë¶„í¬ì˜ í˜¼í•© ëª¨í˜•ì€ ìŒì´í•­ ë¶„í¬ (Negative Binomial Distribution) ë¼ê³ ë„ ë¶€ë¥¸ë‹¤. ë‘ ë¶„í¬ë¥¼ í•¨ê»˜ ì‚¬ìš©í•œë‹¤ëŠ” ê±´ í¬ì•„ì†¡ì˜ ëª¨ìˆ˜ê°€ ê°ë§ˆ ë¶„í¬ë¥¼ ë”°ë¥´ë„ë¡ ë§Œë“œëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. í¬ì•„ì†¡ ë¶„í¬ì˜ ëª¨ìˆ˜ëŠ” ì¼ì •í•œ ê¸°ê°„ ë™ì•ˆì˜ ì¬êµ¬ë§¤ìœ¨ì´ê³ , ê³ ê°ë§ˆë‹¤ ì¬êµ¬ë§¤ìœ¨ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ê°ë§ˆë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•œë‹¤.   \\[ğ‘‹ \\sim ğ‘ƒğ‘œğ‘–ğ‘ ğ‘ ğ‘œğ‘›(\\lambda_i)\\]  \\[\\lambda_i \\sim ğºğ‘ğ‘šğ‘šğ‘(\\alpha, \\beta)\\]  ê´€ë ¨ ê¸°ì´ˆ í†µê³„ ë¶„í¬ ê°œë…ì •ë¦¬:   í¬ì•„ì†¡ ë¶„í¬: ë‹¨ìœ„ ì‹œê°„ ë™ì•ˆì˜ ì„±ê³µ íšŸìˆ˜ì— ëŒ€í•œ ë¶„í¬ (ê¸°ê°„ì„ ì–´ë–»ê²Œ ì •ì˜í•˜ëƒì— ë”°ë¼ â€˜Rateâ€™ë¡œë„ í‘œí˜„ ê°€ëŠ¥)   ê°ë§ˆ ë¶„í¬: ì‚¬ê±´ì„ në²ˆ ì‹œí–‰í•  ë•Œê¹Œì§€ì˜ ì´ ì‹œê°„ì„ ë¶„í¬ (ì§€ìˆ˜ ë¶„í¬ëŠ” íŠ¹ìˆ˜í•œ ì¼€ì´ìŠ¤)   ìŒì´í•­ ë¶„í¬: ì‚¬ê±´ì´ në²ˆ ë°œìƒí•  ë•Œê¹Œì§€ì˜ ì‹œí–‰í•˜ëŠ” ê²½ìš°ì˜ ì‹œí–‰ íšŸìˆ˜ì˜ ë¶„í¬ (ê¸°í•˜ ë¶„í¬ëŠ” íŠ¹ìˆ˜í•œ ì¼€ì´ìŠ¤)         4. Modified Poisson-Gamma (MPG) ëª¨ë¸   \\[\\lambda_{A_{i,}C_{j}} = \\frac{k + \\alpha_{A_i}}{t_{purch} + 2 \\cdot |t_{mean} - t| + \\beta_{A_i}}\\]  \\(t_{purch}\\): ì²« êµ¬ë§¤ë¶€í„° ë§ˆì§€ë§‰ êµ¬ë§¤ê¹Œì§€ì˜ ê¸°ê°„   \\(t_{mean}\\): í‰ê·  ì¬êµ¬ë§¤ ê°„ê²©   \\(t\\): ë§ˆì§€ë§‰ êµ¬ë§¤ë¶€í„° ì§‘ê³„ì¼ê¹Œì§€ì˜ ê¸°ê°„   ë³€í˜•ëœ í¬ì•„ì†¡-ê°ë§ˆ í˜¼í•© ëª¨í˜•ì€ í•˜ë‚˜ì˜ ì¬êµ¬ë§¤ìœ¨ \\(\\lambda\\) ëª¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³ , \\(\\lambda\\)  ëŠ” ê³ ê°ì´ ê°€ì¥ ìµœê·¼ì— ì¬êµ¬ë§¤í•œ ì œí’ˆ \\(A_i\\)ì˜ Time ê³¼ Dependent í•˜ë‹¤ê³  ê°€ì •í•œë‹¤. ê·¸ë¦¬ê³  PG ëª¨í˜•ê³¼ ë™ì¼í•˜ê²Œ ì¬êµ¬ë§¤ìœ¨ì€ ê°ë§ˆë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³ ë„ ê°€ì •í•œë‹¤. (MPG ëª¨ë¸ì—ì„œì˜ \\(\\lambda\\) ëŠ” \\(t&lt;2 âˆ— t_{mean}\\) ì¼ ë•Œë§Œ ì‚¬ìš©í•œë‹¤ )   í¬ì•„ì†¡ ëª¨ìˆ˜(\\(\\lambda\\))ëŠ” t = 0 to t = \\(t_{mean}\\)  ì¼ ë•Œ ì»¤ì§€ê³ , t = \\(t_{mean}\\)  to t = 2 âˆ— \\(t_{mean}\\) ì¼ë•ŒëŠ” ì‘ì•„ì§€ëŠ” êµ¬ì¡°ì´ë‹¤. ê³ ê°ì´ í‰ê· ì ìœ¼ë¡œ ì œí’ˆ \\(A_i\\)  ë¥¼ ì¬êµ¬ë§¤ í•˜ëŠ” ì‹œê°„ ê°„ê²©ê³¼ ê°€ê¹Œì›Œì§€ë©´ ì¬êµ¬ë§¤ìœ¨ì´ ë†’ì•„ì§€ê³ , ë©€ì–´ì§ˆ ìˆ˜ë¡ ì¬êµ¬ë§¤ìœ¨ì´ ë‚®ì•„ì§€ê²Œ ë§Œë“¤ì–´ì¡Œë‹¤.   \\[P_{A_i} (t_{k+1}=t\\ | \\ t_1, t_2, t_3, â€¦, t_k)â‰ˆQ(A_i) \\cdot R_{A_{i,}C_{j}}(t)\\]  where \\(Q(A_i) = ğ‘…ğ¶ğ‘ƒ_{ğ´_ğ‘–}= \\frac{\\# \\ customers \\ who \\ bought \\  product \\ ğ´_ğ‘– \\ more \\ than \\ once}{\\# \\ customers \\ who \\ bought \\  product \\ ğ´_ğ‘– \\ at \\ least \\ once}\\)   \\(RCP_{A_i}\\) ì€ time-independent signal ë„ ì¶”ì²œëª¨ë¸ì— í™œìš©í•œë‹¤. íŠ¹ì • ìƒí’ˆì„ ì¬êµ¬ë§¤ í•œë‹¤ëŠ” ê²ƒì€ ì‹ ê·œ ê³ ê° í˜¹ì€ ê¸°ì¡´ ê³ ê°ì„ ë§Œì¡±ì‹œí‚¤ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. ë§Œì•½ \\(RCP_{A_i}\\) ê³„ì‚°ì„ ìƒëµí•˜ê³  ê³ ê°ì´ ìµœê·¼ì— êµ¬ë§¤í•œ ì œí’ˆì„ ë°”íƒ•ì„ ì¶”ì²œì„ í•œë‹¤ë©´ sub-optimal í•œ ê³ ê°ê²½í—˜ì„ ì œê³µí•˜ê²Œ ëœë‹¤.   Offline Experiments ê²°ê³¼        ATD, PG, ê·¸ë¦¬ê³  MPG ëª¨ë¸ì´ RCP ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ìŒ.   PG/MPG ì€ ì´ êµ¬ë§¤ í–‰ë™ íŒ¨í„´ ì™¸ì— ê³ ê°ì˜ êµ¬ë§¤ ì‹ í˜¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì„œ RCP/ATD ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ìŒ.   Time-dependent/independent signal ë¥¼ ëª¨ë‘ ì‚¬ìš©í•œ MPG ëª¨ë¸ì´ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ìŒ.   OnlineExperiments ê²°ê³¼        ê¸°ì¡´ ì¶”ì²œëª¨ë¸ë³´ë‹¤ ATD ëª¨ë¸ì´ CTR 7.1% ë†’ìŒ   ATD ëª¨ë¸ë³´ë‹¤ MPG ëª¨ë¸ì´ CTR 1.3% ë†’ìŒ   ì˜¤í”„ë¼ì¸ ì‹¤í—˜ì—ì„œì˜ ê²°ê³¼ì™€ ì¼ì¹˜í•¨ (ATD &lt; MPG ì„±ëŠ¥)   Reference:      https://assets.amazon.science/40/e5/89556a6341eaa3d7dacc074ff24d/buy-it-again-modeling-repeat-purchase-recommendations.pdf  ","categories": ["Statistics"],
        "tags": ["Marketing Science"],
        "url": "/statistics/buyitagain",
        "teaser": null
      },{
        "title": "[Transformer] Attention Is All You Need",
        "excerpt":"Introduction   RNN, LSTM, ê·¸ë¦¬ê³  GRU í™œìš© ëª¨ë¸ì€ ê¸°ê³„ë²ˆì—­ ë“±ì˜ ë¬¸ì œì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì˜€ë‹¤. í•˜ì§€ë§Œ RNN ê³„ì—´ ëª¨ë¸ì€ ì¬ê·€ì ì¸ íŠ¹ì„± ë•Œë¬¸ì— ë³‘ë ¬ ì²˜ë¦¬ ì—°ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì´ ì¹˜ëª…ì ì¸ ë‹¨ì ì´ë‹¤. ê·¸ëŸ¬ë©´ RNNì˜ ì–´ë–¤ ì ì´ ì¬ê·€ì ì¸ ê²ƒì¼ê¹Œ? RNN ê³„ì—´ ëª¨ë¸ì€ ì´ì „ ë‹¨ê³„ì—ì„œ ê³„ì‚°í•œ $h_{t-1}$ ë¡œ í˜„ ë‹¨ê³„ì˜ $h_t$ ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë¶€ë¶„ì´ ì¬ê·€ì ì¸ íŠ¹ì„±ì„ ë³´ì—¬ì¤€ë‹¤. ë”°ë¼ì„œ RNN ê³„ì¸µì˜ ìˆœí™˜ êµ¬ì¡°ê°€ ì—°ì‚°ì„ ë³‘ë ¬í™”í•  ìˆ˜ ì—†ê²Œ ë§Œë“ ë‹¤. ê·¸ë¦¬ê³  RNN ê³„ì—´ ëª¨ë¸ì€ ë˜ í•œê°€ì§€ì˜ ë¬¸ì œì ì´ ì¡´ì¬í•œë‹¤. ì…ë ¥ê³¼ ì¶œë ¥ ê°„ì˜ ëŒ€ì‘ë˜ëŠ” ë‹¨ì–´ë“¤ ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ë©€ìˆ˜ë¡ ê·¸ ê´€ê³„ë¥¼ ëª¨ë¸ì´ ì˜ í•™ìŠµí•˜ì§€ ëª»í•œë‹¤ (Long-term dependency problem). ì´ëŸ¬í•œ ë‹¨ì ì„ ë³´ì™„í•˜ê³ ì seq2seq êµ¬ì¡°ì—ì„œì˜ Attentionë§Œì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë°”ë¡œ Transformer ë¼ê³ í•œë‹¤.   Transformer Architecture     ì§€ê¸ˆê¹Œì§€ì˜ Transduction (ë³€í™˜) ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ RNN ê³„ì—´ì˜ encoder-decoder êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆëŠ” ë°˜ë©´, Transformerì€ encoder-decoder êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ê·¸ ë‚´ë¶€ëŠ” attention ê³¼ point-wise feed forward network ë§Œìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.   Encoder-Decoder Stacks   EncoderëŠ” ë™ì¼í•œ ë ˆì´ì–´ì˜ êµ¬ì„±ìœ¼ë¡œ 6ê°œê°€ stacked ë˜ì–´ìˆê³ , ê° ë ˆì´ì–´ëŠ” ì•„ë˜ 2ê°œì˜ ì„œë¸Œë ˆì´ì–´ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.      Multi-head self-attention   position-wise fully connected feed-forward network   ê° ì„œë¸Œë ˆì´ì–´ì˜ ì¶œë ¥ê°’ì€ $LayerNorm(x + SubLayer(x))$ ìœ¼ë¡œ skip connection ê³¼ normalization ì„ ì ìš©í–ˆë‹¤.   Decoderì€ 6ê°œì˜ ë™ì¼í•œ ë ˆì´ì–´ë¡œ stacked ë˜ì–´ìˆì§€ë§Œ, 3 ê°œì˜ ì„œë¸Œë ˆì´ì–´ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.      Multi-head self-attention   Masked Multi-head self-attention   position-wise fully connected feed-forward network   Encoderì™€ ë™ì¼í•˜ê²Œ skip connectionì™€ normalizationì„ ì‚¬ìš©í•˜ê³ , Decoderê°€ ì¶œë ¥ê°’ì„ ìƒì„±í•  ë•Œ ë‹¤ìŒ ì¶œë ¥(ë¯¸ë˜)ì—ì„œ ì •ë³´ë¥¼ ì–»ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ maskingì„ ì‚¬ìš©í•œë‹¤.   Attention &amp; Multi-head Attention     Scaled Dot-Product Attention ì˜ ì…ë ¥ê°’ìœ¼ë¡œ $d_k$ ì°¨ì›ì˜ query-keyì™€ $d_v$ ì°¨ì›ì˜ valueê°€ ë“¤ì–´ê°„ë‹¤. ê°€ì¥ ë¨¼ì € queryì™€ keyì˜ dot product ì„ ê³„ì‚°í•˜ê³ , $\\sqrt{d_k}$ë¡œ ë‚˜ëˆˆ ê°’ì„ softmax í•¨ìˆ˜ë¥¼ í†µí•´ values ì˜ ê°€ì¤‘ì¹˜ ê°’ì„ êµ¬í•œë‹¤. ì—¬ê¸°ì„œ $\\frac{1}{\\sqrt{d_k}}$ ê°’ì„ ê³±í•´ì£¼ì§€ ì•Šìœ¼ë©´ additive attention ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤ê³  í•œë‹¤.   \\[Attention(Q, K, V) = softmax(\\frac{Q \\cdot K^T}{\\sqrt{d_k}})\\cdot V\\]  \\[MultiHead(Q, K, V ) = Concat(head_1, ..., head_h)W^{O}\\]  \\[where \\ \\ head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)\\]  \\[W_i^Q \\in R^{ d_{model} \\times d_k}, W_i^K \\in R^{d_{model} \\times d_k}, W_i^V \\in R^{d_{model} \\times d_v}\\]  ë³¸ ë…¼ë¬¸ì—ì„œëŠ” 8 ê°œì˜ head (attention)  ë¥¼ ì‚¬ìš©í–ˆë‹¤. ê·¸ë¦¬ê³  $d_k$ = $d_v$ = $\\frac{d_{model}}{h}$ = 64 ë¥¼ ì‚¬ìš©í–ˆë‹¤.   Point-wise Feed forward Network   Multi-head self attention ë ˆì´ì–´ì—ì„œ ì¶œë ¥ëœ ê°’ì„ ì…ë ¥ ê°’ìœ¼ë¡œ ë°›ê³ , ReLU í™œì„±í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. Point-wise Feed Forward Network (FFN) ì˜ ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤ (ì´ëŠ” conv 1 x 1 ì—°ì‚°ì„ ë‘ ë²ˆí•˜ëŠ” ê²ƒë„ ë™ì¼í•˜ë‹¤).   \\[FFN(x) = max(0, xW_i + b_1)W_2 + b_2\\]  Positional Encoding   Transformer ì—ì„œëŠ” RNN ê³„ì—´ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— sequenceì— ìˆëŠ” ì›ì†Œë“¤ì˜ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë„ í•¨ê»˜ ë„£ì–´ì¤˜ì•¼ í•œë‹¤. ê·¸ë˜ì„œ Encoderì™€ Decoderì´ ì‹œì‘í•˜ê¸° ì „ì— positional encodingë¥¼ ì…ë ¥í•˜ê³  embeddingì— ë”í•´ì¤€ë‹¤. ëª¨ë¸ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œ ê²ƒì€ ì‚¬ì¸ê³¼ ì½”ì‚¬ì¸í•¨ìˆ˜ì´ë‹¤.   \\[PE_{(pos,2i)}=sin\\bigg(\\frac{pos}{10000^{\\frac{2i}{dmodel}}}\\bigg)\\]  \\[PE_{(pos,2i + 1)}=cos\\bigg(\\frac{pos}{10000^{\\frac{2i}{dmodel}}}\\bigg)\\]  Results   Machine Translation (EN-DE &amp; EN-FR) ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ì´ë‹¤. Transformer (base model)ë§Œ ë´ë„ EN-DE ê¸°ê³„ë²ˆì—­ ë¬¸ì œì—ì„œ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤¬ê³ , íŠ¹íˆ Transformer (big) ì€ EN-DE/EN-FR ê¸°ê³„ë²ˆì—­ ë¬¸ì œì—ì„œ ëª¨ë‘  state-of-the-artë¥¼ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ ì£¼ì—ˆë‹¤.     Tensorflow ì‹¤ìŠµ   íŠ¸ëœìŠ¤í¬ë¨¸ ì±—ë´‡ ì½”ë“œ: https://github.com/ukairia777/tensorflow-transformer   import pandas as pd import urllib.request import tensorflow_datasets as tfds import tensorflow as tf import time import numpy as np import matplotlib.pyplot as plt import re  # urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")  train_data = pd.read_csv('./ChatBotData.csv')  # ì„œë¸Œì›Œë“œí…ìŠ¤íŠ¸ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ëª¨ë‘ í¬í•¨í•œ ë‹¨ì–´ ì§‘í•©(Vocabulary) ìƒì„± tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(     train_data['Q'] + train_data['A'], target_vocab_size=2**13)  # ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì— ëŒ€í•œ ì •ìˆ˜ ë¶€ì—¬. START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]  # ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ê³ ë ¤í•˜ì—¬ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë¥¼ + 2 VOCAB_SIZE = tokenizer.vocab_size + 2  print('ì‹œì‘ í† í° ë²ˆí˜¸ :',START_TOKEN) print('ì¢…ë£Œ í† í° ë²ˆí˜¸ :',END_TOKEN) print('ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° :',VOCAB_SIZE)  sample_string = train_data['Q'][0] # encode() : í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ --&gt; ì •ìˆ˜ ì‹œí€€ìŠ¤ tokenized_string = tokenizer.encode(sample_string) print ('ì •ìˆ˜ ì¸ì½”ë”© í›„ì˜ ë¬¸ì¥ {}'.format(tokenized_string))  # decode() : ì •ìˆ˜ ì‹œí€€ìŠ¤ --&gt; í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ original_string = tokenizer.decode(tokenized_string) print ('ê¸°ì¡´ ë¬¸ì¥: {}'.format(original_string))  # ìµœëŒ€ ê¸¸ì´ë¥¼ 40ìœ¼ë¡œ ì •ì˜ MAX_LENGTH = 40  # í† í°í™” / ì •ìˆ˜ ì¸ì½”ë”© / ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í° ì¶”ê°€ / íŒ¨ë”© def tokenize_and_filter(inputs, outputs):     tokenized_inputs, tokenized_outputs = [], []      for (sentence1, sentence2) in zip(inputs, outputs):     # encode(í† í°í™” + ì •ìˆ˜ ì¸ì½”ë”©), ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í° ì¶”ê°€         sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN         sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN          tokenized_inputs.append(sentence1)         tokenized_outputs.append(sentence2)      # íŒ¨ë”©     tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(         tokenized_inputs, maxlen=MAX_LENGTH, padding='post')     tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(         tokenized_outputs, maxlen=MAX_LENGTH, padding='post')          return tokenized_inputs, tokenized_outputs  questions, answers = tokenize_and_filter(train_data['Q'], train_data['A']) print('ì§ˆë¬¸ ë°ì´í„°ì˜ í¬ê¸°(shape) :', questions.shape) print('ë‹µë³€ ë°ì´í„°ì˜ í¬ê¸°(shape) :', answers.shape)  # í…ì„œí”Œë¡œìš° datasetì„ ì´ìš©í•˜ì—¬ ì…”í”Œ(shuffle)ì„ ìˆ˜í–‰í•˜ë˜, ë°°ì¹˜ í¬ê¸°ë¡œ ë°ì´í„°ë¥¼ ë¬¶ëŠ”ë‹¤. # ë˜í•œ ì´ ê³¼ì •ì—ì„œ êµì‚¬ ê°•ìš”(teacher forcing)ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ë””ì½”ë”ì˜ ì…ë ¥ê³¼ ì‹¤ì œê°’ ì‹œí€€ìŠ¤ë¥¼ êµ¬ì„±í•œë‹¤. BATCH_SIZE = 64 BUFFER_SIZE = 20000  # ë””ì½”ë”ì˜ ì‹¤ì œê°’ ì‹œí€€ìŠ¤ì—ì„œëŠ” ì‹œì‘ í† í°ì„ ì œê±°í•´ì•¼ í•œë‹¤. dataset = tf.data.Dataset.from_tensor_slices((     {         'inputs': questions,         'dec_inputs': answers[:, :-1] # ë””ì½”ë”ì˜ ì…ë ¥. ë§ˆì§€ë§‰ íŒ¨ë”© í† í°ì´ ì œê±°ëœë‹¤.     },     {         'outputs': answers[:, 1:]  # ë§¨ ì²˜ìŒ í† í°ì´ ì œê±°ëœë‹¤. ë‹¤ì‹œ ë§í•´ ì‹œì‘ í† í°ì´ ì œê±°ëœë‹¤.     }, ))  dataset = dataset.cache() dataset = dataset.shuffle(BUFFER_SIZE) dataset = dataset.batch(BATCH_SIZE) dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # ìµœì¢… ë²„ì „ class PositionalEncoding(tf.keras.layers.Layer):     def __init__(self, position, d_model):         super(PositionalEncoding, self).__init__()         self.pos_encoding = self.positional_encoding(position, d_model)      def get_angles(self, position, i, d_model):         angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))         return position * angles      def positional_encoding(self, position, d_model):         angle_rads = self.get_angles(             position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],             i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],             d_model=d_model)          # ë°°ì—´ì˜ ì§ìˆ˜ ì¸ë±ìŠ¤(2i)ì—ëŠ” ì‚¬ì¸ í•¨ìˆ˜ ì ìš©         sines = tf.math.sin(angle_rads[:, 0::2])          # ë°°ì—´ì˜ í™€ìˆ˜ ì¸ë±ìŠ¤(2i+1)ì—ëŠ” ì½”ì‚¬ì¸ í•¨ìˆ˜ ì ìš©         cosines = tf.math.cos(angle_rads[:, 1::2])          angle_rads = np.zeros(angle_rads.shape)         angle_rads[:, 0::2] = sines         angle_rads[:, 1::2] = cosines         pos_encoding = tf.constant(angle_rads)         pos_encoding = pos_encoding[tf.newaxis, ...]          print(pos_encoding.shape)         return tf.cast(pos_encoding, tf.float32)      def call(self, inputs):         return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]      def scaled_dot_product_attention(query, key, value, mask):     # query í¬ê¸° : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     # key í¬ê¸° : (batch_size, num_heads, keyì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     # value í¬ê¸° : (batch_size, num_heads, valueì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     # padding_mask : (batch_size, 1, 1, keyì˜ ë¬¸ì¥ ê¸¸ì´)      # Qì™€ Kì˜ ê³±. ì–´í…ì…˜ ìŠ¤ì½”ì–´ í–‰ë ¬.     matmul_qk = tf.matmul(query, key, transpose_b=True)      # ìŠ¤ì¼€ì¼ë§     # dkì˜ ë£¨íŠ¸ê°’ìœ¼ë¡œ ë‚˜ëˆ ì¤€ë‹¤.     depth = tf.cast(tf.shape(key)[-1], tf.float32)     logits = matmul_qk / tf.math.sqrt(depth)      # ë§ˆìŠ¤í‚¹. ì–´í…ì…˜ ìŠ¤ì½”ì–´ í–‰ë ¬ì˜ ë§ˆìŠ¤í‚¹ í•  ìœ„ì¹˜ì— ë§¤ìš° ì‘ì€ ìŒìˆ˜ê°’ì„ ë„£ëŠ”ë‹¤.     # ë§¤ìš° ì‘ì€ ê°’ì´ë¯€ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì§€ë‚˜ë©´ í–‰ë ¬ì˜ í•´ë‹¹ ìœ„ì¹˜ì˜ ê°’ì€ 0ì´ ëœë‹¤.     if mask is not None:         logits += (mask * -1e9)      # ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” ë§ˆì§€ë§‰ ì°¨ì›ì¸ keyì˜ ë¬¸ì¥ ê¸¸ì´ ë°©í–¥ìœ¼ë¡œ ìˆ˜í–‰ëœë‹¤.     # attention weight : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, keyì˜ ë¬¸ì¥ ê¸¸ì´)     attention_weights = tf.nn.softmax(logits, axis=-1)      # output : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     output = tf.matmul(attention_weights, value)      return output, attention_weights  class MultiHeadAttention(tf.keras.layers.Layer):    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):     super(MultiHeadAttention, self).__init__(name=name)     self.num_heads = num_heads     self.d_model = d_model      assert d_model % self.num_heads == 0      # d_modelì„ num_headsë¡œ ë‚˜ëˆˆ ê°’.     # ë…¼ë¬¸ ê¸°ì¤€ : 64     self.depth = d_model // self.num_heads      # WQ, WK, WVì— í•´ë‹¹í•˜ëŠ” ë°€ì§‘ì¸µ ì •ì˜     self.query_dense = tf.keras.layers.Dense(units=d_model)     self.key_dense = tf.keras.layers.Dense(units=d_model)     self.value_dense = tf.keras.layers.Dense(units=d_model)      # WOì— í•´ë‹¹í•˜ëŠ” ë°€ì§‘ì¸µ ì •ì˜     self.dense = tf.keras.layers.Dense(units=d_model)    # num_heads ê°œìˆ˜ë§Œí¼ q, k, vë¥¼ splití•˜ëŠ” í•¨ìˆ˜   def split_heads(self, inputs, batch_size):     inputs = tf.reshape(         inputs, shape=(batch_size, -1, self.num_heads, self.depth))     return tf.transpose(inputs, perm=[0, 2, 1, 3])    def call(self, inputs):     query, key, value, mask = inputs['query'], inputs['key'], inputs[         'value'], inputs['mask']     batch_size = tf.shape(query)[0]      # 1. WQ, WK, WVì— í•´ë‹¹í•˜ëŠ” ë°€ì§‘ì¸µ ì§€ë‚˜ê¸°     # q : (batch_size, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model)     # k : (batch_size, keyì˜ ë¬¸ì¥ ê¸¸ì´, d_model)     # v : (batch_size, valueì˜ ë¬¸ì¥ ê¸¸ì´, d_model)     # ì°¸ê³ ) ì¸ì½”ë”(k, v)-ë””ì½”ë”(q) ì–´í…ì…˜ì—ì„œëŠ” query ê¸¸ì´ì™€ key, valueì˜ ê¸¸ì´ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤.     query = self.query_dense(query)     key = self.key_dense(key)     value = self.value_dense(value)      # 2. í—¤ë“œ ë‚˜ëˆ„ê¸°     # q : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     # k : (batch_size, num_heads, keyì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     # v : (batch_size, num_heads, valueì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     query = self.split_heads(query, batch_size)     key = self.split_heads(key, batch_size)     value = self.split_heads(value, batch_size)      # 3. ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜. ì•ì„œ êµ¬í˜„í•œ í•¨ìˆ˜ ì‚¬ìš©.     # (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads)     scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)     # (batch_size, queryì˜ ë¬¸ì¥ ê¸¸ì´, num_heads, d_model/num_heads)     scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])      # 4. í—¤ë“œ ì—°ê²°(concatenate)í•˜ê¸°     # (batch_size, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model)     concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))      # 5. WOì— í•´ë‹¹í•˜ëŠ” ë°€ì§‘ì¸µ ì§€ë‚˜ê¸°     # (batch_size, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model)     outputs = self.dense(concat_attention)      return outputs  def create_padding_mask(x):   mask = tf.cast(tf.math.equal(x, 0), tf.float32)   # (batch_size, 1, 1, keyì˜ ë¬¸ì¥ ê¸¸ì´)   return mask[:, tf.newaxis, tf.newaxis, :]        def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")    # ì¸ì½”ë”ëŠ” íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")    # ë©€í‹°-í—¤ë“œ ì–´í…ì…˜ (ì²«ë²ˆì§¸ ì„œë¸Œì¸µ / ì…€í”„ ì–´í…ì…˜)   attention = MultiHeadAttention(       d_model, num_heads, name=\"attention\")({           'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V           'mask': padding_mask # íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©       })    # ë“œë¡­ì•„ì›ƒ + ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™”   attention = tf.keras.layers.Dropout(rate=dropout)(attention)   attention = tf.keras.layers.LayerNormalization(       epsilon=1e-6)(inputs + attention)    # í¬ì§€ì…˜ ì™€ì´ì¦ˆ í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ (ë‘ë²ˆì§¸ ì„œë¸Œì¸µ)   outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)   outputs = tf.keras.layers.Dense(units=d_model)(outputs)    # ë“œë¡­ì•„ì›ƒ + ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™”   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)   outputs = tf.keras.layers.LayerNormalization(       epsilon=1e-6)(attention + outputs)    return tf.keras.Model(       inputs=[inputs, padding_mask], outputs=outputs, name=name)        def encoder(vocab_size, num_layers, dff,             d_model, num_heads, dropout,             name=\"encoder\"):   inputs = tf.keras.Input(shape=(None,), name=\"inputs\")    # ì¸ì½”ë”ëŠ” íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")    # í¬ì§€ì…”ë„ ì¸ì½”ë”© + ë“œë¡­ì•„ì›ƒ   embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)    # ì¸ì½”ë”ë¥¼ num_layersê°œ ìŒ“ê¸°   for i in range(num_layers):     outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,         dropout=dropout, name=\"encoder_layer_{}\".format(i),     )([outputs, padding_mask])    return tf.keras.Model(       inputs=[inputs, padding_mask], outputs=outputs, name=name)        # ë””ì½”ë”ì˜ ì²«ë²ˆì§¸ ì„œë¸Œì¸µ(sublayer)ì—ì„œ ë¯¸ë˜ í† í°ì„ Maskí•˜ëŠ” í•¨ìˆ˜ def create_look_ahead_mask(x):   seq_len = tf.shape(x)[1]   look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)   padding_mask = create_padding_mask(x) # íŒ¨ë”© ë§ˆìŠ¤í¬ë„ í¬í•¨   return tf.maximum(look_ahead_mask, padding_mask)       def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")   enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")    # ë””ì½”ë”ëŠ” ë£©ì–´í—¤ë“œ ë§ˆìŠ¤í¬(ì²«ë²ˆì§¸ ì„œë¸Œì¸µ)ì™€ íŒ¨ë”© ë§ˆìŠ¤í¬(ë‘ë²ˆì§¸ ì„œë¸Œì¸µ) ë‘˜ ë‹¤ ì‚¬ìš©.   look_ahead_mask = tf.keras.Input(       shape=(1, None, None), name=\"look_ahead_mask\")   padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')    # ë©€í‹°-í—¤ë“œ ì–´í…ì…˜ (ì²«ë²ˆì§¸ ì„œë¸Œì¸µ / ë§ˆìŠ¤í¬ë“œ ì…€í”„ ì–´í…ì…˜)   attention1 = MultiHeadAttention(       d_model, num_heads, name=\"attention_1\")(inputs={           'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V           'mask': look_ahead_mask # ë£©ì–´í—¤ë“œ ë§ˆìŠ¤í¬       })    # ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™”   attention1 = tf.keras.layers.LayerNormalization(       epsilon=1e-6)(attention1 + inputs)    # ë©€í‹°-í—¤ë“œ ì–´í…ì…˜ (ë‘ë²ˆì§¸ ì„œë¸Œì¸µ / ë””ì½”ë”-ì¸ì½”ë” ì–´í…ì…˜)   attention2 = MultiHeadAttention(       d_model, num_heads, name=\"attention_2\")(inputs={           'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V           'mask': padding_mask # íŒ¨ë”© ë§ˆìŠ¤í¬       })    # ë“œë¡­ì•„ì›ƒ + ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™”   attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)   attention2 = tf.keras.layers.LayerNormalization(       epsilon=1e-6)(attention2 + attention1)    # í¬ì§€ì…˜ ì™€ì´ì¦ˆ í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ (ì„¸ë²ˆì§¸ ì„œë¸Œì¸µ)   outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)   outputs = tf.keras.layers.Dense(units=d_model)(outputs)    # ë“œë¡­ì•„ì›ƒ + ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™”   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)   outputs = tf.keras.layers.LayerNormalization(       epsilon=1e-6)(outputs + attention2)    return tf.keras.Model(       inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],       outputs=outputs,       name=name)        def decoder(vocab_size, num_layers, dff,             d_model, num_heads, dropout,             name='decoder'):   inputs = tf.keras.Input(shape=(None,), name='inputs')   enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')    # ë””ì½”ë”ëŠ” ë£©ì–´í—¤ë“œ ë§ˆìŠ¤í¬(ì²«ë²ˆì§¸ ì„œë¸Œì¸µ)ì™€ íŒ¨ë”© ë§ˆìŠ¤í¬(ë‘ë²ˆì§¸ ì„œë¸Œì¸µ) ë‘˜ ë‹¤ ì‚¬ìš©.   look_ahead_mask = tf.keras.Input(       shape=(1, None, None), name='look_ahead_mask')   padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')    # í¬ì§€ì…”ë„ ì¸ì½”ë”© + ë“œë¡­ì•„ì›ƒ   embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)    # ë””ì½”ë”ë¥¼ num_layersê°œ ìŒ“ê¸°   for i in range(num_layers):     outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,         dropout=dropout, name='decoder_layer_{}'.format(i),     )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])    return tf.keras.Model(       inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],       outputs=outputs,       name=name)       def transformer(vocab_size, num_layers, dff,                 d_model, num_heads, dropout,                 name=\"transformer\"):    # ì¸ì½”ë”ì˜ ì…ë ¥   inputs = tf.keras.Input(shape=(None,), name=\"inputs\")    # ë””ì½”ë”ì˜ ì…ë ¥   dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")    # ì¸ì½”ë”ì˜ íŒ¨ë”© ë§ˆìŠ¤í¬   enc_padding_mask = tf.keras.layers.Lambda(       create_padding_mask, output_shape=(1, 1, None),       name='enc_padding_mask')(inputs)    # ë””ì½”ë”ì˜ ë£©ì–´í—¤ë“œ ë§ˆìŠ¤í¬(ì²«ë²ˆì§¸ ì„œë¸Œì¸µ)   look_ahead_mask = tf.keras.layers.Lambda(       create_look_ahead_mask, output_shape=(1, None, None),       name='look_ahead_mask')(dec_inputs)    # ë””ì½”ë”ì˜ íŒ¨ë”© ë§ˆìŠ¤í¬(ë‘ë²ˆì§¸ ì„œë¸Œì¸µ)   dec_padding_mask = tf.keras.layers.Lambda(       create_padding_mask, output_shape=(1, 1, None),       name='dec_padding_mask')(inputs)    # ì¸ì½”ë”ì˜ ì¶œë ¥ì€ enc_outputs. ë””ì½”ë”ë¡œ ì „ë‹¬ëœë‹¤.   enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,       d_model=d_model, num_heads=num_heads, dropout=dropout,   )(inputs=[inputs, enc_padding_mask]) # ì¸ì½”ë”ì˜ ì…ë ¥ì€ ì…ë ¥ ë¬¸ì¥ê³¼ íŒ¨ë”© ë§ˆìŠ¤í¬    # ë””ì½”ë”ì˜ ì¶œë ¥ì€ dec_outputs. ì¶œë ¥ì¸µìœ¼ë¡œ ì „ë‹¬ëœë‹¤.   dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,       d_model=d_model, num_heads=num_heads, dropout=dropout,   )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])    # ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì„ ìœ„í•œ ì¶œë ¥ì¸µ   outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)   small_transformer = transformer(     vocab_size = 9000,     num_layers = 4,     dff = 512,     d_model = 128,     num_heads = 4,     dropout = 0.3,     name=\"small_transformer\")  tf.keras.utils.plot_model(     small_transformer, to_file='small_transformer.png', show_shapes=True)  def loss_function(y_true, y_pred):   y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))    loss = tf.keras.losses.SparseCategoricalCrossentropy(       from_logits=True, reduction='none')(y_true, y_pred)    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)   loss = tf.multiply(loss, mask)    return tf.reduce_mean(loss)   class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):   def __init__(self, d_model, warmup_steps=4000):     super(CustomSchedule, self).__init__()     self.d_model = d_model     self.d_model = tf.cast(self.d_model, tf.float32)     self.warmup_steps = warmup_steps    def __call__(self, step):     arg1 = tf.math.rsqrt(step)     arg2 = step * (self.warmup_steps**-1.5)      return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)  tf.keras.backend.clear_session()  # Hyper-parameters NUM_LAYERS = 2 D_MODEL = 256 NUM_HEADS = 8 DFF = 512 DROPOUT = 0.1  model = transformer(     vocab_size=VOCAB_SIZE,     num_layers=NUM_LAYERS,     dff=DFF,     d_model=D_MODEL,     num_heads=NUM_HEADS,     dropout=DROPOUT)  MAX_LENGTH = 40  learning_rate = CustomSchedule(D_MODEL)  optimizer = tf.keras.optimizers.Adam(     learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)  def accuracy(y_true, y_pred):   # ensure labels have shape (batch_size, MAX_LENGTH - 1)   y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))   return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])   EPOCHS = 5  model.fit(dataset, epochs=EPOCHS)  def evaluate(sentence):   sentence = preprocess_sentence(sentence)    sentence = tf.expand_dims(       START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)    output = tf.expand_dims(START_TOKEN, 0)    # ë””ì½”ë”ì˜ ì˜ˆì¸¡ ì‹œì‘   for i in range(MAX_LENGTH):     predictions = model(inputs=[sentence, output], training=False)      # í˜„ì¬(ë§ˆì§€ë§‰) ì‹œì ì˜ ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ë°›ì•„ì˜¨ë‹¤.     predictions = predictions[:, -1:, :]     predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)      # ë§Œì•½ ë§ˆì§€ë§‰ ì‹œì ì˜ ì˜ˆì¸¡ ë‹¨ì–´ê°€ ì¢…ë£Œ í† í°ì´ë¼ë©´ ì˜ˆì¸¡ì„ ì¤‘ë‹¨     if tf.equal(predicted_id, END_TOKEN[0]):       break      # ë§ˆì§€ë§‰ ì‹œì ì˜ ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ì¶œë ¥ì— ì—°ê²°í•œë‹¤.     # ì´ëŠ” forë¬¸ì„ í†µí•´ì„œ ë””ì½”ë”ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  ì˜ˆì •ì´ë‹¤.     output = tf.concat([output, predicted_id], axis=-1)    return tf.squeeze(output, axis=0)  def preprocess_sentence(sentence):   sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)   sentence = sentence.strip()   return sentence  def predict(sentence):   prediction = evaluate(sentence)    predicted_sentence = tokenizer.decode(       [i for i in prediction if i &lt; tokenizer.vocab_size])    print('Input: {}'.format(sentence))   print('Output: {}'.format(predicted_sentence))    return predicted_sentence  output = predict('ì˜í™” ë³¼ë˜?')   Reference:      https://jalammar.github.io/illustrated-transformer/   https://arxiv.org/abs/1706.03762  ","categories": ["Deep Learning"],
        "tags": ["Natural Language Processing"],
        "url": "/deeplearning/transformer",
        "teaser": null
      },{
        "title": "[ViT] Transformers For Image Recognition at Scale",
        "excerpt":"Introduction   Attention ê³„ì—´ êµ¬ì¡°ëŠ” ìì—°ì–´ ì²˜ë¦¬ë¶„ì•¼ì— ë§ì´ ì‚¬ìš©ë˜ì–´ ì™”ë‹¤. í•˜ì§€ë§Œ ë¹„ì „ ë¶„ì•¼ì—ì„œëŠ” CNN ê³„ì—´ ëª¨ë¸ì´ ìš°ì„¸í•˜ê²Œ ì‚¬ìš©ë˜ê³  ìˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Transformerë¥¼ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì— ì ìš©í•œ ì—°êµ¬ ì‹¤í—˜ì„ ê¸°ìˆ í–ˆë‹¤.   Model Architecture         ì „ì²´ì ì¸ ViT ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” â€˜All You Need Is Attentionâ€™ ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¤ëŠ” Transformer Encoder êµ¬ì¡°ì™€ ë¹„ìŠ·í•˜ë‹¤. ë‹¤ë§Œ í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ì‚¬ìš©í•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” $(H, W, C)$ í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ $N$ ê°œì˜$(P, P)$ íŒ¨ì¹˜ë¡œ ìë¥¸ í›„, ê° íŒ¨ì¹˜ë¥¼ $1D$ sequence í˜•íƒœì¸ $P^2 \\cdot C$ ì°¨ì›ì˜ vectorë¡œ ë§Œë“ ë‹¤. ê·¸ë¦¬ê³  BERTì˜ $[class]$ í† í°ê³¼ ë¹„ìŠ·í•˜ê²Œ, classification tokenì„ Position Embedding[0]ì— ë”í•´ì¤€ ê²ƒì„ Position Embedding[1:] ê³¼ Patch Embeddingì„ ë”í•´ì¤€ ê²ƒì— concatenate í•´ì¤€ë‹¤. ì €ìëŠ” 2D-aware position embeddingsë„ ì‚¬ìš©í•´ë´¤ëŠ”ë° ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ë˜ì§€ ì•Šì•˜ë‹¤ê³  í•œë‹¤.   ê·¸ë¦¬ê³  Transformer Encoderì— Patch + Position Embedding (+ [class] embedding) ê°’ì„ ì…ë ¥ë°ì´í„°ë¡œ ë„£ì–´ì¤€ë‹¤. ìµœì¢…ì ìœ¼ë¡œ Linearì—°ì‚°ì„ í†µí•´ classificationì„ í•˜ê²Œ ëœë‹¤. ì—¬ê¸°ì„œ  Transformer EncoderëŠ” Normalizationì´ ë§¨ ì•ìœ¼ë¡œ ì˜¨ ê²ƒì„ ë¹¼ë©´ ë˜‘ê°™ì€ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•œë‹¤.     Result     ViT Tensorflow ì‹¤ìŠµ ì½”ë“œ   ì°¸ê³ : https://dzlab.github.io/notebooks/tensorflow/vision/classification/2021/10/01/vision_transformer.html   import tensorflow as tf from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add from tensorflow.keras.layers import Input, Embedding, Concatenate from tensorflow.keras.models import Model, Sequential  class Patches(Layer):      # From Keras Examples     def __init__(self, patch_size):         super(Patches, self).__init__()         self.patch_size = patch_size      def call(self, images):         batch_size = tf.shape(images)[0]         patches = tf.image.extract_patches(             images=images,             sizes=[1, self.patch_size, self.patch_size, 1],             strides=[1, self.patch_size, self.patch_size, 1],             rates=[1, 1, 1, 1],             padding=\"VALID\",         )         patch_dims = patches.shape[-1]         patches = tf.reshape(patches, [batch_size, -1, patch_dims])         # print(patches.shape)         return patches  def mlp_head(x, config):     x = Dense(config[\"mlp_head_dim\"] * 2, activation=\"gelu\")(x)     x = Dropout(config[\"dropout_rate\"])(x)     x = Dense(config[\"mlp_head_dim\"])(x)     x = Dropout(config[\"dropout_rate\"])(x)     return x  def transformer_encoder(x, config):     skip_connection_1 = x     x = LayerNormalization()(x)     x = MultiHeadAttention(num_heads=config[\"num_heads\"], key_dim=config[\"embedding_dim\"])(x, x)     x = Add()([x, skip_connection_1])      skip_connection_2 = x     x = LayerNormalization()(x)     x = mlp_head(x, config)     x = Add()([x, skip_connection_2])      return x  class PatchEncoder(Layer):     def __init__(self):         super(PatchEncoder, self).__init__()         self.num_patches = config[\"num_patches\"]         self.projection_dim = config[\"embedding_dim\"]         w_init = tf.random_normal_initializer()         class_token = w_init(shape=(1, self.projection_dim), dtype=\"float32\")         self.class_token = tf.Variable(initial_value=class_token, trainable=True)         self.projection = Dense(units=self.projection_dim)         self.position_embedding = Embedding(input_dim=self.num_patches+1, output_dim=self.projection_dim)      def call(self, patch):         batch = tf.shape(patch)[0]         # reshape the class token embedins         class_token = tf.tile(self.class_token, multiples = (batch, 1))         class_token = tf.reshape(class_token, (batch, 1, self.projection_dim))         # calculate patches embeddings         patches_embedding = self.projection(patch)         patches_embedding = tf.concat([class_token, patches_embedding], 1)         # calcualte positional embeddings         positions = tf.range(start=0, limit=self.num_patches+1, delta=1)         positions_embed = self.position_embedding(positions)         # add both embeddings         encoded = patches_embedding + positions_embed         return encoded  def ViT(config):     # Inputs and Embedding     input_shape = (config[\"img_size\"], config[\"img_size\"], config[\"num_channels\"])     inputs = Input(input_shape)     p = Patches(config['patch_size'])(inputs)     x = PatchEncoder()(p)       # Encoder     for _ in range(config[\"num_layers\"]):         x = transformer_encoder(x, config)      # Classification head     x = LayerNormalization()(x)     x = x[:, 0, :]     x = Dense(config[\"num_classes\"], activation = \"softmax\")(x)      model = Model(inputs, x)     return model   if __name__ == \"__main__\":     config = {}     config[\"embedding_dim\"] = 64     config[\"mlp_head_dim\"] = 64     config[\"dropout_rate\"] = 0.1     config[\"num_heads\"] = 4     config[\"num_classes\"] = 10     config[\"num_patches\"] = 256         config[\"num_layers\"] = 8         config[\"img_size\"] = 256     config[\"patch_size\"] = 16     config[\"num_channels\"] = 3     config[\"num_classes\"] = 10      model = ViT(config)     img = tf.random.normal(shape=[1, config[\"img_size\"], config[\"img_size\"] , 3])     preds = model(img)     print(preds)  ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/vit",
        "teaser": null
      },{
        "title": "[AutoRec] Autoencoders Meet Collaborative Filtering",
        "excerpt":"AutoRec ëª¨ë¸         AutoRec ëª¨ë¸ì€ Auto-Encoder êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ê³ , ì‚¬ìš©ì ë˜ëŠ” ì•„ì´í…œì¤‘ í•˜ë‚˜ë¡œLatent Featureë¥¼ ë§Œë“¤ì–´ Rating Matrix Completionì„ ìˆ˜í–‰í•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì•„ì´í…œì„ ì„ë² ë”©í•˜ëŠ” ëª¨ë¸ì„ I-AutoRec, ì‚¬ìš©ìë¥¼ ì„ë² ë”©í•˜ëŠ” ëª¨ë¸ì„ U-AutoRec ë¼ê³  ë¶€ë¥¸ë‹¤.   ì‚¬ìš©ì(m ëª…)-ì•„ì´í…œ (n ê°œ) í‰ì  í–‰ë ¬ $R \\in \\mathbb{R}^{m \\times n}$ ì´ ìˆë‹¤ê³  ê°€ì •í•œë‹¤. AutoRec ì€ ì…ë ¥ê°’ $\\mathbf{r^{u}} \\text{ or } \\mathbf{r^{i}}\\in \\mathbb{R}^{d}$ ë¥¼ ë°›ì•„, ì´ë¥¼ ë³µì›í•˜ëŠ” $h(\\mathbf{r^{z}};\\theta)$ ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤.   \\[h(\\mathbf{r^{z}}; \\theta) = f(\\mathbf{W} \\cdot g(\\mathbf{Vr^{z}} + \\boldsymbol{\\mu}) + \\mathbf{b}) \\\\ \\text{where z could be either be } \\mathbf{u} \\text{ or } \\mathbf{i}\\]  ìœ„ ì‹(1)ì—ì„œ $f(\\cdot)$ ê³¼ $g(\\cdot)$ ëŠ” ê°ê° decoderì™€ encoderì˜ í™œì„±í™” í•¨ìˆ˜ì´ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” I-AutoRecë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ, identify functionì„ encoderì˜ í™œì„±í™” í•¨ìˆ˜ë¡œ, sigmoid functionì„ decoderì˜ í™œì„±í™” í•¨ìˆ˜ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ (RMSE)ì´ ê°€ì¥ ì¢‹ì•˜ë‹¤ê³  í•œë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ AutoRec ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ëª©ì í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. ì—¬ê¸°ì„œ ëª©ì í•¨ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ observed ratings $\\mathcal{{O}}$ë§Œ ê³ ë ¤í•œë‹¤ëŠ” ê²ƒì´ë‹¤.   \\[\\min_\\theta \\sum^n_{z=1} \\| \\mathbf{r}^{(z)} - h(\\mathbf{r}^{(z)}; \\theta) \\|^2_\\mathcal{O} + \\frac{\\lambda}{2} \\left( \\| \\mathbf{W}_F^2 \\| + \\| \\mathbf{V} \\|^2_F \\right)\\]  Result     AutoRec Tensorflow Implementation   import tensorflow as tf from tensorflow.keras.layers import Dense, Input, Layer from tensorflow.keras import Model, Sequential, regularizers, optimizers, metrics  from zipfile import ZipFile from pathlib import Path import pandas as pd import numpy as np from sklearn.model_selection import train_test_split  class Encoder(Layer):     def __init__(self, num_hidden):         super(Encoder, self).__init__()         self.n_dims = num_hidden         self.encoder_layer = Dense(self.n_dims, activation = None, kernel_regularizer=regularizers.l2(0.01))          @tf.function     def call(self, inputs):         return self.encoder_layer(inputs)      class Decoder(Layer):     def __init__(self, num_reconstruction):         super(Decoder, self).__init__()         self.n_dims = num_reconstruction         self.decoder_layer = Dense(self.n_dims, activation = 'sigmoid')         # self.decoder_layer = Dense(self.n_dims)              @tf.function     def call(self, inputs):         x = self.decoder_layer(inputs)         return x  class AutoRec(Model):     def __init__(self, num_hidden, num_reconstruction):         super(AutoRec, self).__init__()         self.encoder = Encoder(num_hidden)         self.decoder = Decoder(num_reconstruction)      @tf.function            def call(self, inputs):         x = self.encoder(inputs)         x = self.decoder(x)         return x      def ObservedOnlyMSELoss(y_true, y_pred):     # ì°¸ê³ : https://supkoon.tistory.com/36     mask = y_true != 0     mask_float = tf.cast(mask, tf.float32)     masked_error = tf.reduce_mean(tf.pow(tf.subtract(mask_float * y_pred,y_true),2))     return masked_error   movielens_data_file_url = (     \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\" ) movielens_zipped_file = tf.keras.utils.get_file(     \"ml-latest-small.zip\", movielens_data_file_url, extract=False ) keras_datasets_path = Path(movielens_zipped_file).parents[0] movielens_dir = keras_datasets_path / \"ml-latest-small\"  # Only extract the data the first time the script is run. if not movielens_dir.exists():     with ZipFile(movielens_zipped_file, \"r\")as zip:         # Extract files         print(\"Extracting all the files now...\")         zip.extractall(path=keras_datasets_path)         print(\"Done!\")  class dataloader():     # ì°¸ê³ : https://github.com/supkoon/AutoRec-tf/blob/master/AutoRec.py     def __init__(self,test_size, path = movielens_dir / \"ratings.csv\"):         self.test_size = test_size         self.ratings_df = pd.read_csv(path)         self.ratings_df.columns = [\"userId\",\"movieId\",\"rating\",\"timestamp\"]         self.num_user = len(self.ratings_df.userId.unique())         self.num_item = len(self.ratings_df.movieId.unique())              def make_user_autorec_input(self):         user_item_df = self.ratings_df.pivot_table(values=\"rating\", index=\"userId\", columns=\"movieId\")         user_item_df.fillna(0,inplace=True)         self.user_item_df = np.array(user_item_df)         train_df,test_df = train_test_split(self.user_item_df, test_size =self.test_size)         return train_df,test_df      def make_item_autorec_input(self):         item_user_df = self.ratings_df.pivot_table(values=\"rating\", index=\"movieId\", columns=\"userId\")         item_user_df.fillna(0,inplace=True)         self.item_user_df = np.array(item_user_df)         train_df,test_df = train_test_split(self.item_user_df, test_size =self.test_size)         return train_df,test_df      dataloader = dataloader(0.1)    train_data, test_data = dataloader.make_item_autorec_input() num_features = dataloader.num_user  model = AutoRec(num_features // 2, num_features) model.compile(optimizer=optimizers.SGD(learning_rate=0.001), loss= ObservedOnlyMSELoss, metrics = [metrics.RootMeanSquaredError()]) model.fit(train_data, train_data, batch_size=16, epochs=10, validation_data=(test_data, test_data))   Reference:      http://users.cecs.anu.edu.au/~u5098633/papers/www15.pdf   https://keras.io/examples/structured_data/collaborative_filtering_movielens/  ","categories": ["Deep Learning"],
        "tags": ["Recommender System"],
        "url": "/deeplearning/autorec",
        "teaser": null
      },{
        "title": "[BERT] Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "excerpt":"Introduction   BERT(Bidirectional Encoder Representations from Transformers)ëŠ” 2018ë…„ì— êµ¬ê¸€ ë¦¬ì„œì¹˜ íŒ€ì— ì˜í•´ ê³µê°œëœ Language Representation ëª¨ë¸ì´ë‹¤. ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ BERT ëª¨ë¸ì€ ì–‘ë°©í–¥ì„± (Bidirectional) íŠ¹ì„±ì„ ê°–ê³  ìˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–‘ë°©í˜• ë¬¸ë§¥ì„ ê³ ë ¤í•œë‹¤ëŠ” ê²ƒì— ë¬´ìŠ¨ ì˜ë¯¸ì´ê³ , ì–´ë–¤ ì¥ì ì´ ìˆì„ê¹Œ? ì–‘ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì€ ì „ì²´ì ì¸ ë¬¸ë§¥ì„ íŒŒì•…í•˜ê¸° ìœ„í•¨ì´ë‹¤. ì§ê´€ì ìœ¼ë¡œ ìƒê°í•´ë³´ë©´ ë‹¨ë°©í–¥ì—ì„œ ì˜¤ëŠ” ì •ë³´ë³´ë‹¤ ì–‘ë°©í–¥ì—ì„œ ì˜¤ëŠ” ì •ë³´ê°€ ë§ê¸° ë•Œë¬¸ì— ì •ë³´ì˜ ì§ˆì— ì°¨ì´ê°€ ë‚  ìˆ˜ ë°–ì— ì—†ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œShe is eating a bowl of saladâ€ë¼ëŠ” ë¬¸ì¥ì´ ìˆì„ ë•Œ, â€œeatâ€ë¼ëŠ” ë™ì‚¬ë¥¼ ì •í•´ë†“ê³  â€œsaladâ€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. â€œsaladâ€ë¥¼ ë†“ê³  ì–´ë–¤ ì•¡ì…˜ì„ í•˜ê³  ìˆë‹¤ëŠ” ë§ì„ í•˜ê³  ì‹¶ì—ˆì„ ìˆ˜ë„ ìˆë‹¤. ì´ë ‡ë“¯ ì–‘ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•˜ë©´ ì „ì²´ì ì¸ ë¬¸ë§¥ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤.   BERT Architecture       BERTëŠ” Transformerì˜ Encoder ë¶€ë¶„ë§Œ ì‚¬ìš©í•œë‹¤. BERTëŠ” êµ¬ì¡°ì˜ í¬ê¸°ì— ë”°ë¼ Baseì™€ Large 2ê°€ì§€ ìœ í˜•ì˜ ëª¨ë¸ë¡œ ë‚˜ëˆ ì§„ë‹¤. BERT-Base ëª¨ë¸ì˜ HyperparameterëŠ” $L = 12$, $H = 768$, $A = 12$ ì´ê³  BERT-Large ëª¨ë¸ì˜ HyperparameterëŠ” $L = 24$, $H = 1024$, $A = 16$ ì´ë‹¤.      L = # Transformer Block   H = # Hidden Layer   A = # Self Attention Head   ë”í•˜ì—¬ BERTëŠ” ê¸°ì¡´ì˜ ìì—°ì–´ì²˜ë¦¬ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì˜ ë¬¸ì œì ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ unsupervised tasks: (1) Masked language model, (2) next sentence prediction (NSP) ë°©ë²•ì„ ì‚¬ìš©í•´ í•™ìŠµí•œë‹¤.       Masked Language Model (MLM)   MLM ëŠ” [Mask]ëœ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë©´ì„œ ì „ì²´ì ì¸ ë¬¸ë§¥ì„ íŒŒì•…í•˜ëŠ” ëŠ¥ë ¥ì„ í•™ìŠµí•œë‹¤. MLM ìˆ˜í–‰ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ìš°ì„  ì…ë ¥ ë°ì´í„°ì˜ í† í° ì¤‘ 15%ëŠ” ë¬´ì‘ìœ„ë¡œ ì„ íƒí•œë‹¤. ì„ íƒëœ í† í°ì¤‘ 80% [Mask] í† í°ìœ¼ë¡œ, 10%ëŠ” ëœë¤í•œ ë‹¨ì–´ë¡œ ë°”ë€ë‹¤. ê·¸ë¦¬ê³  ë‚˜ë¨¸ì§€ 10%ëŠ” ì˜¤ë¦¬ì§€ë„í•œ ë‹¨ì–´ ê·¸ ìƒíƒœ ê·¸ëŒ€ë¡œ ìœ ì§€ëœë‹¤.   Next Sentence Prediction (NSP)   NSPëŠ” ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ ë‹¤ìŒìœ¼ë¡œ ì˜¤ëŠ” ë¬¸ì¥ì¸ì§€ ë§ì¶”ëŠ” ë¬¸ì œë¥¼ í‘¼ë‹¤. ì²« ë²ˆì§¸ ë¬¸ì¥ê³¼ ë‘ ë²ˆì§¸ ë¬¸ì¥ì€ [SEP]ë¡œ êµ¬ë¶„í•œë‹¤. ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ì„ ì—°ì†í•˜ëŠ”ì§€ëŠ” 50% ë¹„ìœ¨ë¡œ ì°¸ì¸ ë¬¸ì¥ê³¼, 50%ì˜ ëœë¤í•˜ê²Œ ì¶”ì¶œëœ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•´ í•™ìŠµí•œë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ë¬¸ë§¥ê³¼ ë¬¸ì¥ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.   BERT Input           ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ì„¸ ê°€ì§€ ì„ë² ë”©(Token, Segment, Position)ì„ ì‚¬ìš©í•´ì„œ ë¬¸ì¥ì„ í‘œí˜„í•œë‹¤.      Token Embedding: ëª¨ë“  ë¬¸ì¥ì˜ ì‹œì‘ì„ í‘œí˜„í•˜ëŠ” íŠ¹ìˆ˜ í† í° [CLS], ë¬¸ì¥ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ íŠ¹ìˆ˜ í† í° [SEP], ê·¸ë¦¬ê³  ë‹¨ì–´ë³„ ì„ë² ë”©ìœ¼ë¡œ êµ¬ì„±   Segment Embedding: ë¬¸ì¥ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ì„ë² ë”©   Position Embedding: Transformer êµ¬ì¡°ì—ì„œ ì‚¬ìš©ëœ í† í°ì˜ ìœ„ì¹˜ë¥¼  ì•Œë ¤ì£¼ëŠ” ì„ë² ë”©   ì´ ì„¸ ê°€ì§€ ì„ë² ë”©ì„ ë”í•œ ì„ë² ë”©ì„ ì…ë ¥ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.   BERT, GPT, ELMo Comparison       Results   GLUE ë°ì´í„°ì…‹ì— ëŒ€í•œ BERT ì‹¤í—˜ ê²°ê³¼       BERT Tensorflow Code Example   https://www.tensorflow.org/text/tutorials/classify_text_with_bert   # !pip install -q -U \"tensorflow-text==2.8.*\" # !pip install -q tf-models-official==2.7.0 import os import shutil  import tensorflow as tf import tensorflow_hub as hub import tensorflow_text as text from official.nlp import optimization  # to create AdamW optimizer  import matplotlib.pyplot as plt  tf.get_logger().setLevel('ERROR')  url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'  dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,                                   untar=True, cache_dir='.',                                   cache_subdir='')  dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')  train_dir = os.path.join(dataset_dir, 'train')  # remove unused folders to make it easier to load the data remove_dir = os.path.join(train_dir, 'unsup') shutil.rmtree(remove_dir)  AUTOTUNE = tf.data.AUTOTUNE batch_size = 32 seed = 42  raw_train_ds = tf.keras.utils.text_dataset_from_directory(     'aclImdb/train',     batch_size=batch_size,     validation_split=0.2,     subset='training',     seed=seed)  class_names = raw_train_ds.class_names train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)  val_ds = tf.keras.utils.text_dataset_from_directory(     'aclImdb/train',     batch_size=batch_size,     validation_split=0.2,     subset='validation',     seed=seed)  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)  test_ds = tf.keras.utils.text_dataset_from_directory(     'aclImdb/test',     batch_size=batch_size)  test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)  tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1' tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3' bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess) bert_model = hub.KerasLayer(tfhub_handle_encoder)  def build_classifier_model():   text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')   encoder_inputs = preprocessing_layer(text_input)   encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')   outputs = encoder(encoder_inputs)   net = outputs['pooled_output'] # CLS   net = tf.keras.layers.Dropout(0.1)(net)   net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)   return tf.keras.Model(text_input, net)  classifier_model = build_classifier_model() loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) metrics = tf.metrics.BinaryAccuracy()  epochs = 5 steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy() num_train_steps = steps_per_epoch * epochs num_warmup_steps = int(0.1*num_train_steps)  init_lr = 3e-5 optimizer = optimization.create_optimizer(init_lr=init_lr,                                           num_train_steps=num_train_steps,                                           num_warmup_steps=num_warmup_steps,                                           optimizer_type='adamw')  classifier_model.compile(optimizer=optimizer,                          loss=loss,                          metrics=metrics)  history = classifier_model.fit(x=train_ds,                                validation_data=val_ds,                                epochs=epochs)  examples = [     'this is such an amazing movie!',  # this is the same sentence tried earlier     'The movie was great!',     'The movie was meh.',     'The movie was okish.',     'The movie was terrible...' ]  original_results = tf.sigmoid(classifier_model(tf.constant(examples)))  print('Results from the model in memory:') print_my_examples(examples, original_results)   Reference:      https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270   https://hwiyong.tistory.com/392   https://keep-steady.tistory.com/19  ","categories": ["Deep Learning"],
        "tags": ["Natural Language Processing"],
        "url": "/deeplearning/bert",
        "teaser": null
      },{
        "title": "[NeuMF] Neural Collaborative Filtering",
        "excerpt":"Introduction   ë„·í”Œë¦­ìŠ¤ ê²½ì§„ëŒ€íšŒì˜í•´ ì•Œë ¤ì§„ Matrix Factorizationì€ ì¶”ì²œì‹œìŠ¤í…œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì´ë‹¤. ì´ëŠ” ì‚¬ìš©ìì™€ ì•„ì´í…œì´ ìƒí˜¸ì‘ìš©í•˜ëŠ” Latent Matrixì„ Inner Productë¥¼ í†µí•´ ì‚¬ìš©ìì˜ Latent Matrixê³¼ ì•„ì´í…œì˜ Latent Matrixë¡œ ë¶„í•´í•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Inner Product ê¸°ë°˜ì˜ Matrix Factorizationì€ ì„ í˜•ì ì¸ ê´€ê³„ë§Œ ëª¨ë¸ë§í•œë‹¤ëŠ” í•œê³„ì— ëŒ€í•´ ì§€ì í•˜ê³ , ì‚¬ìš©ìì™€ ì•„ì´í…œê°„ì˜ ê´€ê³„ë¥¼ ë” ì˜ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ì‹ ê²½ë§ ê¸°ë°˜ì˜ NeuMF ëª¨ë¸ì„ ì œì•ˆí–ˆë‹¤.   Matrix Factorization ë¬¸ì œì      ìœ„ ê·¸ë¦¼(a)ì€ ì‚¬ìš©ì(row)-ì•„ì´í…œ(column) ê´€ê³„ë¥¼ í–‰ë ¬ë¡œ í‘œí˜„í•˜ê³  ìˆë‹¤. ì—¬ê¸°ì„œ $y_{u,i}=1$ì€ user $u$ ì™€ item $i$ ê°„ì˜ ìƒí˜¸ì‘ìš©ì´ ìˆì—ˆìŒì„ ë‚˜íƒ€ë‚¸ë‹¤. ìƒí˜¸ì‘ìš©ì´ë€ ì‚¬ìš©ìê°€ ì•„ì´í…œì„ í™•ì¸í–ˆê±°ë‚˜, êµ¬ë§¤í–ˆë‹¤ëŠ” ë“±ì˜ implicit í•œ ì •ë³´ë¥¼ ì˜ë§ˆí•œë‹¤. ë”°ë¼ì„œ $y_{u,i}=0$ ì€ user $u$ ì™€ item $i$ ê°„ì˜ ìƒí˜¸ì‘ìš©ì´ ì—†ì—ˆë‹¤ëŠ” ëœ»ì´ì§€, user $u$ ê°€ item $i$ ë¥¼ ì„ í˜¸í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ëœ»ì€ ì•„ë‹ˆë‹¤.   Inner Product ê¸°ë°˜ì˜ Matrix Factorizationì— ì–´ë–¤ ë¬¸ì œê°€ ìˆëŠ”ì§€ ìì¹´ë“œ ìœ ì‚¬ë„(Jaccard Similarity) ë¥¼ ê³ ë ¤í•˜ëŠ” ê²½ìš°ë¥¼ ê°€ì •í•œë‹¤.ê·¸ëŸ¬ë©´ ìœ„ ê·¸ë¦¼(a)ì™€ ê°™ì€ í–‰ë ¬ë¡œë¶€í„° ë‹¤ìŒê³¼ ê°™ì€ ê´€ê³„ê°€ ì„±ë¦½í•œë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.   \\[s_{23}(0.66) &gt; s_{12}(0.5) &gt; s_{13}(0.4)\\]  ì¦‰, ì‚¬ìš©ì 2ì™€ ì‚¬ìš©ì 3ì´ ì‚¬ìš©ì 1ê³¼ ì‚¬ìš©ì 2 ë³´ë‹¤ ë¹„ìŠ·í•˜ê³ , ì‚¬ìš©ì 1ê³¼ ì‚¬ìš©ì 2ì´ ì‚¬ìš©ì 1ê³¼ ì‚¬ìš©ì 3 ë³´ë‹¤ ë¹„ìŠ·í•˜ë‹¤ëŠ” ëœ»ì´ë‹¤. ìœ„ ê·¸ë¦¼ (b) ëŠ” ì´ëŸ° ê´€ê³„ë¥¼ ê¸°í•˜í•™ì ìœ¼ë¡œ ë³´ì—¬ì£¼ê³  ìˆë‹¤. Matrix Factorization ì˜ í•œê³„ëŠ” ì‚¬ìš©ì 4ê°€ ë“±ì¥í–ˆì„ ë•Œ ë°œìƒí•œë‹¤. ì‚¬ìš©ì 4ì™€ ë‚˜ë¨¸ì§€ ì‚¬ìš©ìì˜ ìì¹´ë“œ ìœ ì‚¬ë„ ê´€ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.   \\[s_{41}(0.6) &gt; s_{43}(0.4) &gt; s_{42}(0.2)\\]  í•˜ì§€ë§Œ ê·¸ë¦¼ (b)ì—  $p_4$ë¥¼ ì–´ë””ì— ë†”ë„ $p_3$ë³´ë‹¤ $p_2$ê°€ ë” ê°€ê¹ê¸° ë•Œë¬¸ì— ranking lossê°€ ì»¤ì§ˆ ìˆ˜ ë°–ì— ì—†ë‹¤. ì´ëŸ° í•œê³„ëŠ” ì‚¬ìš©ìì™€ ì•„ì´í…œì˜ ê´€ê³„ë¥¼ ì €ì°¨ì›ì˜ ê³µê°„ì— í‘œí˜„ í•˜ëŠ” ë°ì—ì„œ ê¸°ì¸í•œë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì‚¬ìš©ìì™€ ì•„ì´í…œì˜ ìƒí˜¸ì‘ìš©ì„ ë” ë³µì¡í•œ ì°¨ì›ì—ì„œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ì‹ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ì‹ ê²½ë§ì„ í™œìš©í•´ í•´ê²°í•˜ê³ ì í–ˆë‹¤.   Neural Collaborative Filtering Framework     ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ Neural Collaboraitive Filteringì˜ General Framework ëŠ” ì´ 4ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì—ˆë‹¤: (1) Input Layer, (2) Embedding Layers, (3) Neural CF Layers, ê·¸ë¦¬ê³  (4) Output Layers.   Input LayerëŠ” ê°ê° ì‚¬ìš©ì($v_u^U$)ì™€ ì•„ì´í…œ($v_i^I$)ì„ ë‚˜íƒ€ë‚´ëŠ” ì›í•«ì¸ì½”ë””ë“œëœ Feature vectorë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Embedding Layer ì—ì„œ Sparseí•œ ì´ Feature vectorë¥¼ Denseí•œ Latent vectorë¡œ ë°”ê¿”ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ì„ë² ë”©ì´ ëœ ì‚¬ìš©ìì™€ ì•„ì´í…œ Latent vectorë¥¼ concatenationí•œ vectorë¥¼ Neural CF Layersì— ë“¤ì–´ê°€ê²Œ ë˜ê³  ë³µì¡í•˜ê³  ë¹„ì„ í˜•ì ì¸ ë°ì´í„° ê´€ê³„ë¥¼ í•™ìŠµí•˜ê²Œ ëœë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ Output Layersì—ì„œ ì‚¬ìš©ì $u$ì™€ ì•„ì´í…œ $i$ê°€ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” $\\hat{y_{u,i}}$ ê°’ì„ ê³„ì‚°í•œë‹¤.   Generalized Matrix Factorization (GMF)   ì €ìëŠ” Matrix Factorization ì—­ì‹œ NCF frameworkì˜ íŠ¹ìˆ˜í•œ ì¼€ì´ìŠ¤ê°€ ë¨ì„ ë³´ì—¬ì£¼ê³  ì´ë¥¼ GMFë¼ê³  í•œë‹¤. Latent Vector $p_u$ ($P^Tv^U_u$), $q_i$ ($Q^Tv^I_i$) ë¼ê³  ì •ì˜í–ˆì„ ë•Œ, ì²«ë²ˆì§¸ NCF layerì˜ mapping functionì„ ë‹¤ìŒê³¼ ê°™ë‹¤.   \\[\\phi_1(p_u,q_i) = p_u\\odot q_i\\]  ì´ ê²°ê³¼ë¥¼ output layerì— projectí•œë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ $a_{out}$ ë¥¼ identical functionìœ¼ë¡œ ê°€ì •í•˜ê³ , $h$ë¥¼ uniform vector 1ë¡œ ì •ì˜í•œë‹¤ë©´, ê¸°ì¡´ Matrix Factorizationê³¼ ë™ì¼í•´ì§‘ë‹ˆë‹¤.   \\[\\hat{y}_{ui} = a_{out}(h^T(p_u \\odot q_i))\\]  GMFë€ $a_{out}$ ì™€ $h$ë¥¼ ì•„ë˜ì™€ ê°™ì´ ë‘ì–´ Matrix Factorizationë¥¼ ì¼ë°˜í™”í•œ ëª¨ë¸ì´ë‹¤.   \\[a_{out} = \\frac{1}{1 + e^{âˆ’x}},\\ h^T = [h_1 , ... , h_k],\\]  Multi-Layer Perceptron (MLP)   GMFì˜ fixed/linear (element-wise product)í•œ íŠ¹ì§•ìœ¼ë¡œ ì¸í•´ ì‚¬ìš©ìì™€ ì•„ì´í…œê°„ì˜ ë³µì¡í•œ ê´€ê³„ë¥¼ í‘œí˜„í•˜ì§€ ëª»í•˜ê³ , MLPëŠ” flexible/non-linearí•˜ê¸° ë•Œë¬¸ì— ë³µì¡í•œ ê´€ê³„ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.   \\[z_1 = \\phi_1(p_u,q_i) = \\begin{bmatrix}p_u\\\\q_i\\end{bmatrix},\\\\ \\phi_2(z_1) = a_2(W_2^Tz_1+b_2), \\\\ ... \\\\ \\phi_L(z_{L-1}) = a_L(W_L^Tz_{L-1}+b_L), \\\\ \\hat{y}_{ui} = \\sigma(h^T\\phi_L(Z_{L-1}))\\]  Fusion of GMF and MLP   ë³¸ ë…¼ë¬¸ì—ì„œëŠ” GMFì™€ MLPë¥¼ í†µí•©í•œ ëª¨ë¸ì€ ì œì•ˆí•œë‹¤.   \\[\\phi^{GMF} = p_{u}^{G} \\odot q_{i}^{G}, \\\\ \\phi^{MLP} = a_{L}(W_{L}^{T}(a_{L-1}(...a_{2}(W_{2}^{T} \\begin{bmatrix} p_{u}^{M} \\\\ q_{i}^{M} \\end{bmatrix}+b_{2})...))+b_{L}), \\\\ \\hat{y}_{u,i} = \\sigma(h^{T} \\begin{bmatrix}\\phi^{GMF} \\\\ \\phi^{MLP} \\end{bmatrix})\\]  $p^G_u$ì™€ $q^G_i$ëŠ” GMFë¥¼ ìœ„í•œ embeddingì´ê³  $p^M_u$ì™€ $q^M_i$ëŠ” MLPë¥¼ ìœ„í•œ embeddingì´ë‹¤. ê·¸ë¦¬ê³  $a_L$ í™œì„±í™” í•¨ìˆ˜ë¡œ ReLUë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤.   Result     NMF ëª¨ë¸ Tensorflow ì‹¤ìŠµ   class NeuMF(Model):     def __init__(self, user_num, item_num, latent_features = 8, alpha = 0.5):         super(NeuMF, self).__init__()         self.latent_features = latent_features         self.user_num = user_num         self.item_num = item_num         self.alpha = alpha                  self.gmf_embedding_user = Embedding(input_dim = self.user_num, output_dim = self.latent_features)         self.gmf_embedding_item = Embedding(input_dim = self.item_num, output_dim = self.latent_features)         self.mlp_embedding_user = Embedding(input_dim = self.user_num, output_dim = 32)         self.mlp_embedding_item = Embedding(input_dim = self.item_num, output_dim = 32)                  self.mlp_vector1 = Dense(units=16, activation='relu')         self.mlp_vector2 = Dense(units=8, activation='relu')                  self.prediction = Dense(1, activation='sigmoid')              def call(self, inputs):         user_input, item_input = inputs          # Embedding layer         gmf_embedding_user = self.gmf_embedding_user(user_input)         gmf_embedding_item = self.gmf_embedding_user(item_input)         mlp_embedding_user = self.gmf_embedding_user(user_input)         mlp_embedding_item = self.gmf_embedding_user(item_input)          # GMF part         gmf_user_latent = Flatten()(gmf_embedding_user)         gmf_item_latent = Flatten()(gmf_embedding_item)         gmf_vector = Multiply()([gmf_user_latent, gmf_item_latent])                   # MLP part          mlp_user_latent = Flatten()(mlp_embedding_user)         mlp_item_latent = Flatten()(mlp_embedding_item)         mlp_vector = Concatenate()([mlp_user_latent, mlp_item_latent])                  mlp_vector1 = self.mlp_vector1(mlp_vector)         mlp_vector2 = self.mlp_vector2(mlp_vector1)                  # Concatenate GMF and MLP parts         gmf_vector = Lambda(lambda x: x * self.alpha)(gmf_vector)         mlp_vector2 = Lambda(lambda x : x * (1-self.alpha))(mlp_vector2)         prediction_vector = Concatenate()([gmf_vector, mlp_vector2])                  # Prediction Layer         return self.prediction(prediction_vector)  def train_instances(uids, iids, num_neg, num_items):     user_input, item_input, labels = [],[],[]     zipped = set(zip(uids, iids)) # train (user, item) ì„¸íŠ¸      for (u, i) in zip(uids, iids):          # pos item         user_input.append(u)          item_input.append(i)           labels.append(1)             # neg item         for t in range(num_neg):              j = np.random.randint(num_items)              while (u, j) in zipped:                  j = np.random.randint(num_items)               user_input.append(u)  # [u1, u1,  u1,  ...]             item_input.append(j)  # [pos_i, neg_j1, neg_j2, ...]             labels.append(0)      # [1, 0,  0,  ...]      user_input = np.array(user_input).reshape(-1, 1)     item_input = np.array(item_input).reshape(-1, 1)     labels = np.array(labels).reshape(-1, 1)     return user_input, item_input, labels  num_neg = 4 # train_user_ids: í•™ìŠµ ë°ì´í„°ì˜ ìœ ì € ì•„ì´ë”” (unique) # train_item_ids: í•™ìŠµ ë°ì´í„°ì˜ ì•„ì´í…œ ì•„ì´ë”” (unique) # items: í•™ìŠµ + í…ŒìŠ¤íŠ¸ì˜ ì•„ì´í…œ ì•„ì´ë”” train_user_ids, train_item_ids, items = load_dataset() # ë¡œë“œë°ì´í„° ê°ì êµ¬í˜„ í•„ìš”  user_input, item_input, labels = train_instances(train_user_ids, train_item_ids, num_neg, len(items))  model = NeuMF(len(users), len(items))  model.compile(optimizer= 'adam', loss='binary_crossentropy') model.fit([user_input, item_input],labels, batch_size=128, epochs=10, shuffle=True)   Reference:      https://github.com/ngduyanhece/neuMF/blob/master/NeuMF.py   https://leehyejin91.github.io/post-ncf/   https://supkoon.tistory.com/28  ","categories": ["Deep Learning"],
        "tags": ["Recommender System"],
        "url": "/deeplearning/neuralcf",
        "teaser": null
      },{
        "title": "[FM] Factorization Machines",
        "excerpt":"Introduction   ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í¬ì†Œì„±ì´ ë†’ì€ ë°ì´í„° í™˜ê²½ì—ì„œë„ realiable parameterë¥¼ ì¶”ì •í•  ìˆ˜ ìˆëŠ” Factorization Machine (FM) ëª¨ë¸ì„ ì†Œê°œí•œë‹¤. FM ì•Œê³ ë¦¬ì¦˜ì€ Support Vector Machineì˜ ì¥ì ê³¼ Factorization Modelì˜ ì¥ì ë§Œì„ ê²°í•©í•œ ëª¨ë¸ì´ë‹¤. ë”°ë¼ì„œ FM ëª¨ë¸ì˜ ì¥ì ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.      Highly Sparse data = í¬ì†Œí•œ ë°ì´í„° í™˜ê²½ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì •ì´ ê°€ëŠ¥í•˜ë‹¤ (Factorization Modelâ€™s ì¥ì ).   Linear Complexity = Feature ê°œìˆ˜ì— ë”°ë¥¸ ì„ í˜• ë³µì¡ë„ë¥¼ ê°–ëŠ”ë‹¤.   General Predictor = ì‹¤ìˆ˜ë‚˜ ì •ìˆ˜ê°’ì„ ì…ë ¥ë°ì´í„°ë¡œ ë„£ì„ ìˆ˜ ìˆë‹¤ (SVMâ€™s ì¥ì ).   Example: Feature Representation        ìœ„ ê·¸ë¦¼ê³¼ ê°™ì€ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •í•´ë³´ì. ê·¸ë¦¼ì—ì„œì˜ íŒŒë€ìƒ‰ ì˜ì—­ì€ ìœ ì €ë¥¼ ì˜ë¯¸í•˜ëŠ” ë³€ìˆ˜ì´ê³ , ì£¼í™©ìƒ‰ ì˜ì—­ì€ ì•„ì´í…œ(ì—¬ê¸°ì„œëŠ” ì˜í™” ì´ë¦„)ì„ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ì´ë‹¤. ë…¸ë€ìƒ‰ ì˜ì—­ì€ ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ì˜í™”ë“¤ì— í‰ì ì„ ì¤€ ë³€ìˆ˜ì´ê³ , ë…¹ìƒ‰ì€ 1ì›” 2009ë…„ ì´í›„ ì›” ë‹¨ìœ„ ì‹œê°„ì„ ë‚˜íƒ€ë‚¸ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë¶‰ì€ìƒ‰ ì˜ì—­ì€ í•´ë‹¹ ì˜í™”ë¥¼ í‰ê°€í•˜ê¸° ì „ì— í‰ê°€í•œ ì˜í™”ë¥¼ ë‚˜íƒœë‚´ëŠ” ë³€ìˆ˜ì´ë‹¤. ê·¸ë¦¬ê³  ë§¨ ì˜¤ë¥¸ìª½ ì—´ì€ ì˜í™”ì— ëŒ€í•œ í‰ì ì´ë‹¤.   ì˜ˆë¥¼ ë“¤ì–´, í‰ì ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ Alice(A)ì™€ StarTrek(ST)ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì„ estimateí•œë‹¤ê³  ê°€ì •í•´ë³´ì. ì¸ìˆ˜ë¶„í•´ëœ ìƒí˜¸ì‘ìš© íŒŒë¼ë¯¸í„°ì¸ $&lt;V_{A}, V_{ST}&gt;$ë¥¼ í†µí•´ ìƒí˜¸ì‘ìš©ì„ ì¸¡ì •í•  ìˆ˜ ìˆë‹¤. ìš°ì„ , Bob(B)ê³¼ Charlie(C) ëª¨ë‘ StarWars(SW)ì— ëŒ€í•œ í‰ì ì„ ê°ì 4ì , 5ì  ì£¼ì—ˆê¸° ë•Œë¬¸ì— ìœ ì‚¬í•œ Factor Vector $V_B$, $V_C$ë¥¼ ê°€ì§„ë‹¤. ì´ê²ƒì€ $&lt;V_{B}, V_{SW}&gt;$ì™€ $&lt;V_{C}, V_{SW}&gt;$ê°€ ìœ ì‚¬í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ê·¸ë¦¬ê³  AliceëŠ” Titanic(TI)ì— 5ì , CharlieëŠ” 1ì ì„ ì£¼ì—ˆê¸° ë•Œë¬¸ì— Aliceì™€ CharlieëŠ” ë‹¤ë¥¸ Factor Vectorë¥¼ ê°€ì§„ë‹¤. ê·¸ë¦¬ê³  Bobì´ StarTrekê³¼ StarWarsì— ìœ ì‚¬í•œ ë†’ì€ ì ìˆ˜ ê°ê° 4ì , 5ì ë¥¼ ì£¼ì—ˆê¸° ë•Œë¬¸ì— ë‘ ì˜í™”ì˜ Factor VectorëŠ” ìœ ì‚¬í•œ ìƒí˜¸ì‘ìš©ì„ ê°€ì§ˆ ê²ƒì´ë‹¤. ê²°ë¡ ì„ ë§í•˜ìë©´, AliceëŠ” StarTrekì— ëŒ€í•´ í‰ì ì„ ë‚®ê²Œ ì¤„ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ Aliceì™€ StarTrekì— ëŒ€í•œ Factor Vectorì˜ ë‚´ì ì´ Aliceì™€ StarWarsì˜ Factor Vectorì˜ ë‚´ì ê°’ê³¼ ìœ ì‚¬í•˜ë‹¤ëŠ” ì ì„ ì¶”ì¸¡í•  ìˆ˜ ìˆë‹¤.   Model Equation  degree d=2ì¸ FM ì•Œê³ ë¦¬ì¦˜ ë°©ì •ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.   \\[\\hat{y}(x) := w_{0} + \\sum_{i=1}^{n} w_{i}x_{i} + \\sum_{i=1}^{n}\\sum_{j= i + 1}^{n} &lt;v_i,v_j&gt;x_ix_j \\\\ \\text{where the model parameters that have to be estimated are:} \\\\ w_{0} \\in \\mathbb{R}, \\mathbf{w} \\in \\mathbb{R}^n, \\mathbf{V} \\in \\mathbb{R}^{n \\times k}\\]  ìœ„ ì‹ì˜ ì²« ë²ˆì§¸ í•­ $w_{0}$ì€ global biasì´ë‹¤. ë‘ë²ˆì§¸ í•­ì„ ë³´ë©´ $w_{i}$ëŠ” ië²ˆì§¸ ê°œë³„ Featureì— ëŒ€í•œ ê°€ì¤‘ì¹˜ì´ë©°, $x_{i}$ëŠ” í•˜ë‚˜ì˜ Feature Vectorë¥¼ ì˜ë¯¸í•œë‹¤. ëª¨ë¸ë§ì„ í†µí•´ ê°œë³„ Featureì˜ ì˜í–¥ë ¥(w)ë¥¼ estimateí•˜ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ, Featureë“¤ë¼ë¦¬ì— ëŒ€í•œ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•  ìˆ˜ ì—†ë‹¤ëŠ” ë‹¨ì ì´ ìˆì–´ì„œ ì„¸ ë²ˆì§¸ í•­ì¸ $&lt;V_i, V_j&gt;$ ì´ ì¶”ê°€ë˜ì—ˆìœ¼ë©° ì´ëŠ” ië²ˆì§¸ì™€ jë²ˆì§¸ Featureê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ì˜ë¯¸í•œë‹¤. ì¤‘ìš”í•œ ê²ƒì€ $w_{i,j}$ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì´ë¥¼ kì°¨ì›ìœ¼ë¡œ ì¸ìˆ˜ë¶„í•´ëœ ë‘ vectorì˜ ë‚´ì ë¥¼ $&lt;V_i, V_j&gt;$ë¡œ í‘œí˜„í•œ ê²ƒì´ë‹¤. ì´ê²ƒì€ ë³€ìˆ˜ê°„ ìƒí˜¸ì‘ìš©ì˜ Latent Vector ì´ë‹¤.   \\[&lt;v_i, v_j&gt; := \\sum_{f = 1}^{k}v_{i,f} \\cdot v_{j, f}\\]  $v_i$ëŠ” V ë‚´ë¶€ì˜ í–‰ì„ ì˜ë¯¸í•˜ê³  kê°œì˜ factorë¥¼ ê°€ì§„ ië²ˆì§¸ ë³€ìˆ˜ì´ë©°, këŠ” factorizationì˜ ì°¨ì›ì´ë‹¤. ì´ëŠ” Latent Vector ì¡°í•©ì„ ëª¨ë‘ ê³ ë ¨í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.   Linear Complexity ìœ¼ë¡œ ë§Œë“œëŠ” ì‹ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.    FM ì•Œê³ ë¦¬ì¦˜ Tensorflow   # https://github.com/supkoon/factorization_machine_tf class FM(keras.Model):     def __init__(self, n_factor=8, **kwargs):         super().__init__(**kwargs)          self.w_0 = tf.Variable([0.0])         self.w = tf.Variable(tf.zeros(shape=[n]))         self.v = tf.Variable(tf.random.normal(shape=(n, n_factor)))      def call(self,inputs):         degree_1 = tf.math.reduce_sum(tf.multiply(self.w, inputs), axis=1)          degree_2 = 0.5 * tf.math.reduce_sum(             tf.math.pow(tf.linalg.matmul(inputs, self.v), 2)             - tf.linalg.matmul(tf.math.pow(inputs, 2), tf.math.pow(self.v, 2))             , 1             , keepdims=False         )          predict = tf.math.sigmoid(self.w_0 + degree_1 + degree_2)          return predict   Reference:     https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf   https://www.intelligencelabs.tech/c4d971e3-09a5-4e20-9d82-cc623344602d   ","categories": ["Machine Learning"],
        "tags": ["Recommender System"],
        "url": "/machinelearning/fm",
        "teaser": null
      },{
        "title": "[U-Net] Convolutional Networks for Biomedical Image Segmentation",
        "excerpt":"Introduction   ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¼ë²¨ë§ì€ í•˜ëŠ” ì‘ì—…ì€ ê³ ëœ ê³¼ì •ì´ë‹¤. íŠ¹íˆ ì»´í“¨í„° ë¹„ì „ì—ì„œì˜ ë¶„í•  ë¬¸ì œëŠ” ê° í”½ì…€ì´ ì–´ë–¤ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ ì•Œì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— êµ¬í•˜ê¸°ê°€ ì–´ë µë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë°ì´í„° ìˆ˜ê°€ ì ì–´ë„ ë¶„í•  ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆëŠ” Uìí˜• êµ¬ì¡° U-Netë¥¼ ì†Œê°œí•œë‹¤. ì´ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ëŠ” ìˆ˜ì¶• ê²½ë¡œ (contracting path) ê·¸ë¦¬ê³  í™•ì¥ ê²½ë¡œ (expanding path)ë¡œ í¬ê²Œ ë‚˜ëˆ ì§„ë‹¤. U-Netì€ contracting pathë¥¼ í†µí•´ context ì •ë³´ë¥¼ êµ¬í•˜ê³ , expanding pathë¥¼ í†µí•´ ë‹¤ì‹œ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— segmentation (precise localization) ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.   Architecture:     Contracting Path  ìˆ˜ì¶• ê²½ë¡œëŠ” U-Net êµ¬ì¡°ì—ì„œì˜ ì‹œì‘ ë¶€ë¶„(Concave Up, Decreasing)ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. ì´ë¯¸ì§€ì˜ ê³µê°„í•´ìƒë„ë¥¼ ì¤„ì´ê¸° ìœ„í•œ $2 \\times 2$ Max Pooling (Stride = 2)ê³¼, ReLU í™œì„±í™”í•¨ìˆ˜ë¥¼ í¬í•¨í•œ ë‘ ë²ˆì˜ $3 \\times 3$ Conv (Stride = 1, No Padding) ì—°ì‚°ì„ í•œë‹¤. ì¦‰, $3 \\times 3$ Conv (íŒŒë€ìƒ‰ í™”ì‚´í‘œ) $\\rightarrow$ ReLU í™œì„±í™” í•¨ìˆ˜ $\\rightarrow$ $2 \\times 2$ Max Pooling (Stride = 2, ë¹¨ê°„ìƒ‰ í™”ì‚´í‘œ)ë¥¼ ê° ë ˆë²¨ì—ì„œ ë‘ ë²ˆì”© ì§„í–‰í•˜ë©°, ê³µê°„í•´ìƒë„ëŠ” ì¤„ì´ê³  ì±„ë„ì˜ ê°œìˆ˜ëŠ” 2ë°°ë¡œ ì¦ê°€ì‹œí‚¤ëŠ” ì‘ì—…ì„ ë°˜ë³µì ìœ¼ë¡œ ì§„í–‰í•œë‹¤.   Expanding Path  í™•ì¥ ê²½ë¡œëŠ” U-Net êµ¬ì¡°ì—ì„œì˜ ë’·ë¶€ë¶„(Concave Up, Increasing)ì— í•´ë‹¹ëœë‹¤. í™•ì¥ ê²½ë¡œì—ì„œëŠ” ìˆ˜ì¶• ê²½ë¡œì—ì„œì™€ëŠ” ë‹¤ë¥´ê²Œ ì´ë¯¸ì˜ ê³µê°„í•´ìƒë„ë¥¼ ì¦ê°€ì‹œí‚¤ê¸° ìœ„í•œ ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. ìˆ˜ì¶• ê²½ë¡œì—ì„œ ì¶”ì¶œí•œ íŠ¹ì„±ë§µê³¼ concatenationë¥¼ ì§„í–‰í•œ ë’¤, ReLU í™œì„±í™” í•¨ìˆ˜ë¥¼ í¬í•¨í•œ $2 \\times 2$ Up Convolution ì ìš©í•œë‹¤. ì¦‰, Feature Map Concatenation (íšŒìƒ‰ í™”ì‚´í‘œ) $\\rightarrow$ 2ë²ˆì˜ $2 \\times 2$ Up Convolution (ì´ˆë¡ìƒ‰ í™”ì‚´í‘œ) with ReLUë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©° ê³µê°„í•´ìƒë„ëŠ” ë‹¤ì‹œ ëŠ˜ë¦¬ëŠ” ì‘ì—…ì„ í•œë‹¤.   ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œëŠ” $1 \\times 1$ Conv filter (ì²­ë…¹ìƒ‰ í™”ì‚´í‘œ)ë¥¼ ì´ìš©í•´ í´ë˜ìŠ¤ì˜ ê°œìˆ˜ë§Œí¼ ì±„ë„ì˜ ê°œìˆ˜ë¥¼ ë‚¨ê²¨ì¤€ë‹¤.   Data Augmentation  Data Augmentationì€ invarianceì™€ robustness ì„±ì§ˆì„ í•™ìŠµí•˜ê¸° ìœ„í•œ í•„ìˆ˜ì ì¸ ìš”ì†Œì´ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Random Elastic Deformationì„ ì‚¬ìš©í•œ ê²ƒì´ ë¶„í•  ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµí•˜ëŠ” ë°ì— ìˆì–´ Key Concept ì—­í• ì„ í–ˆë‹¤ê³  í•œë‹¤. ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ ì´ ì¦ê°• ê¸°ë²•ì€ ì´ë¯¸ì§€ë¥¼ ìœ ì—°í•˜ê²Œ ë³€í˜•ì‹œì¼œ í”ë“¤ë¦¼ì´ë‚˜ ì™œê³¡ëœ ì´ë¯¸ì§€ë¥¼ ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆê²Œ ë§Œë“ ë‹¤.   Why U-Net      ì ì€ ìˆ˜ì˜ í•™ìŠµ ë°ì´í„°ë¡œë„ Biomedical Image Segmentation ë¬¸ì œì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„.   ìˆ˜ì¶• ê²½ë¡œë¥¼ ê±°ì¹˜ë©´ì„œ Context ì •ë³´ë¥¼ êµ¬í•˜ê³ , í™•ì¥ ê²½ë¡œë¥¼ í†µí•´ ì •í™•í•œ Localizationì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë¨.   íŒŒì´í”„ë¼ì¸ ë„¤íŠ¸ì›Œí¬ê°€ ì—†ëŠ” End-to-End êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŒ.   Results         U-Net Tensorflow Implementation   # padding = 'same' is used for convenience from tensorflow.keras.layers import Conv2D, Activation, Concatenate from tensorflow.keras.layers import MaxPooling2D, Conv2DTranspose, Input from tensorflow.keras import Model   def conv_blocks(inputs, num_filters):     x = Conv2D(num_filters, 3, padding='same')(inputs)     x = Activation(\"relu\")(x)          x = Conv2D(num_filters, 3, padding='same')(x)     x = Activation(\"relu\")(x)     return x  def contracting_block(inputs, num_filters):     x = conv_blocks(inputs, num_filters)     p = MaxPooling2D((2, 2))(x)     return x, p  def expanding_block(inputs, skip_features, num_filters):     x = Conv2DTranspose(num_filters, (2, 2), strides = 2, padding = \"same\")(inputs)     x = Concatenate()([x, skip_features])     x = conv_blocks(x, num_filters)     return x  def build_unet(input_shape):     inputs = Input(input_shape)          s1, p1 = contracting_block(inputs, 64)     s2, p2 = contracting_block(p1, 128)     s3, p3 = contracting_block(p2, 256)     s4, p4 = contracting_block(p3, 512)          b1 = conv_blocks(p4, 1024)          d1 = expanding_block(b1, s4, 512)     d2 = expanding_block(d1, s3, 256)     d3 = expanding_block(d2, s2, 128)     d4 = expanding_block(d3, s1, 64)          outputs = Conv2D(1, (1, 1), padding = \"same\", activation='sigmoid')(d4)     model = Model(inputs, outputs, name = 'unet')     return model  input_shape = (512, 512, 3) model = build_unet(input_shape) model.summary()   Reference:     https://arxiv.org/abs/1505.0459   https://goeden.tistory.com/74  ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/unet",
        "teaser": null
      },{
        "title": "[Faster R-CNN] Towards Real-Time Object Detection with Region Proposal Networks",
        "excerpt":" ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/fasterrcnn",
        "teaser": null
      },{
        "title": "[USAD] UnSupervised Anomaly Detection on Multivariate Time Series",
        "excerpt":"Introduction   USAD ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…í•˜ê¸° ì•ì„œ Auto-encoder(AE)ì™€ GAN ì—ì„œì˜ ì´ìƒíƒì§€ì˜ ì¥ë‹¨ì ì„ ì•„ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ë¨¼ì € AE ê¸°ë°˜ì˜ ì´ìƒíƒì§€ëŠ” í•™ìŠµ ë‹¨ê³„ì™€ íƒì§€ ë‹¨ê³„ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤. í•™ìŠµ ë‹¨ê³„ì—ì„œëŠ” ëª¨ë¸ì´ ì •ìƒ ë°ì´í„°ë¥¼ ì••ì¶•ê³¼ ë³µì›í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ë©´ì„œ ë³µì›ëœ ë°ì´í„°ì™€ ì›ë³¸ ë°ì´í„° ê°„ì˜ ì°¨ì´(reconstruction error)ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ë§Œë“¤ì–´ì§€ê³ , íƒì§€ ë‹¨ê³„ì—ì„œëŠ” ë¹„ì •ìƒê³¼ ì •ìƒ ë°ì´í„° ëª¨ë‘ ë„£ì–´ íŠ¹ì • threshold (aka anomaly score)ì„ ë„˜ê¸°ë©´ ë¹„ì •ìƒ, ë„˜ê¸°ì§€ ëª»í•˜ë©´ ì •ìƒìœ¼ë¡œ ì´ìƒì—¬ë¶€ë¥¼ íŒë‹¨í•œë‹¤. í•˜ì§€ë§Œ AEëŠ” ì••ì¶•í•˜ëŠ” ê³¼ì •ì—ì„œ ë¶ˆí•„ìš”í•œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê¸° ë•Œë¬¸ì— ë¹„ì •ìƒ ë°ì´í„°ê°€ ì •ìƒ ë°ì´í„°ì™€ ê±°ì˜ ë¹„ìŠ·í•˜ë‹¤ë©´ reconstruction errorëŠ” ì‘ì•„ì§ˆ ê²ƒì´ê³ , ë¹„ì •ìƒìœ¼ë¡œ ê°ì§€ë˜ì§€ ëª»í•  ê²ƒ ì´ë‹¤.   GAN ê¸°ë°˜ì˜ ì´ìƒíƒì§€ ê²½ìš° ì…ë ¥ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³  ë³µì›í•˜ëŠ” ê²ƒì€ Generatorê°€ ë‹´ë‹¹í•œë‹¤. ì´ë•Œ Generatorì˜ ì£¼ëœ ëª©í‘œëŠ” Discriminatorê°€ êµ¬ë¶„í•˜ì§€ ëª»í•  ì •ë„ë¡œ ì‹¤ì œë°ì´í„°ì™€ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ì§€ì†ì ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— Generatorì—ì„œì˜ Encoderì™€ DecoderëŠ” ë¹„ì •ìƒê³¼ ì •ìƒ ë°ì´í„° ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì§€ê³  ìˆë‹¤. ê·¸ë¦¬ê³  DiscriminatorëŠ” Generatorê°€ ìƒì„±ë°ì´í„°ê°€ ë¹„ì •ìƒì¸ì§€ ì •ìƒì¸ì§€ êµ¬ë³„í•˜ëŠ” ì—­í• ì„ í•œë‹¤. í•˜ì§€ë§Œ GAN ëª¨ë¸ë„ ì™„ë²½í•œ ê²ƒì€ ì•„ë‹ˆë‹¤. GANì€ mode-collapseì™€ non-convergenceë¥¼ ë‹¨ì ìœ¼ë¡œ ê°€ì§€ê³  ìˆì–´ ë¶ˆì•ˆì •ì ì¸ ë©´ë„ ìˆë‹¤.   ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  GANê³¼ AE ì¥ì ë§Œìœ¼ë¡œ ë§Œë“  ì´ìƒ íƒì§€ ëª¨ë¸ì´ USADì´ë‹¤.   Architecture    USAD ëŠ” Phase 1 (AE Training) ê³¼ Phase 2 (Adversarial Training) ë‹¨ê³„ë¡œ ì´ë¤„ì ¸ìˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ê°ê°ì˜ AEë¥¼ ì›ë˜ì˜ ì…ë ¥ìœ¼ë¡œ ì˜ ë³µì›ë˜ë„ë¡ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤.ì‹¤ì œë°ì´í„° WëŠ” ì¸ì½”ë” Eì— ì˜í•´ Latent Space Zë¡œ ì••ì¶•ë˜ê³  ê°ê°ì˜ ë””ì½”ë”ì— ì˜í•´ ë³µì›ëœë‹¤. ì´ ë¶€ë¶„ì— í•´ë‹¹ë˜ëŠ” Loss Functionì€ ë‹¤ìŒê³¼ ê°™ë‹¤.   \\[L_{AE_{1}} = ||W - AE_{1}(W)||_2\\]  \\[L_{AE_{2}} = ||W - AE_{2}(W)||_2\\]  ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” $AE_{2}$ê°€ ì‹¤ì œ ë°ì´í„°ì™€ $AE_{1}(W)$ë¥¼ ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµí•œë‹¤. ë°˜ë©´ $AE_{1}$ëŠ” $AE_{2}$ì˜ ì„±ëŠ¥ì„ ì €í•˜ ì‹œí‚¤ë„ë¡ í•™ìŠµëœë‹¤. ì¦‰ $AE_{1}$(GANì˜ Generator)ëŠ” Wì™€ $AE_{2}$ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ê³  $AE_{2}$ (GANì˜ Discriminator)ëŠ” ì´ ì°¨ì´ë¥¼ ìµœëŒ€í™” í•˜ëŠ” ê²ƒì´ë‹¤.   \\[L_{AE_{1}} = +||W - AE_{2}(AE_{1}(W))||_2\\]  \\[L_{AE_{2}} = -||W - AE_{2}(AE_{1}(W))||_2\\]  ìµœì¢… Loss Functionì€ ì•„ë˜ì™€ ê°™ë‹¤.     USAD Tensorflow Implementation   ë°ì´í„°:     https://drive.google.com/open?id=1rVJ5ry5GG-ZZi5yI4x9lICB8VhErXwCw   https://drive.google.com/open?id=1iDYc0OEmidN712fquOBRFjln90SbpaE7   import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  import numpy as np import tensorflow as tf import pandas as pd from tensorflow.keras import Model from tensorflow.keras.layers import Layer, Dense from sklearn.metrics import roc_curve,roc_auc_score, accuracy_score, f1_score from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split from sklearn import preprocessing  CONFIG = {     \"Batch\": 7919,     \"Window\": 12,     \"Hidden\": 100,     \"Epoch\": 100 }  class Encoder(Layer):     def __init__(self, in_size, latent_size):         super(Encoder, self).__init__()         self.linear1 = Dense(int(in_size/2), input_shape=(in_size,), activation = \"relu\")         self.linear2 = Dense(int(in_size/4), input_shape=(int(in_size/2),), activation = \"relu\")         self.linear3 = Dense(latent_size, input_shape=(int(in_size/4),), activation = \"relu\")              def call(self, inputs):         x = self.linear1(inputs)         x = self.linear2(x)         x = self.linear3(x)         return x      class Decoder(Layer):     def __init__(self, latent_size, out_size):         super(Decoder, self).__init__()         self.linear1 = Dense(int(out_size/4), input_shape=(latent_size,), activation = \"relu\")         self.linear2 = Dense(int(out_size/2), input_shape=(int(out_size/4),), activation = \"relu\")         self.linear3 = Dense(out_size, input_shape=(int(out_size/2),), activation = 'sigmoid')      def call(self, inputs):         x = self.linear1(inputs)         x = self.linear2(x)         x = self.linear3(x)         return x  class USAD(Model):     def __init__(self, w_size, z_size):         super(USAD, self).__init__()         self.encoder = Encoder(w_size, z_size)         self.decoder1 = Decoder(z_size, w_size)         self.decoder2 = Decoder(z_size, w_size)              def call(self, inputs, epoch):         z = self.encoder(inputs)         w1 = self.decoder1(z)         w2 = self.decoder2(z)         w3 = self.decoder2(self.encoder(w1))         loss1 = 1/epoch*tf.reduce_mean((inputs-w1)**2)+(1-1/epoch)*tf.reduce_mean((inputs-w3)**2)         loss2 = 1/epoch*tf.reduce_mean((inputs-w2)**2)-(1-1/epoch)*tf.reduce_mean((inputs-w3)**2)         return loss1, loss2   def generate_dataset(batch_size, window_size):     normal = pd.read_csv(\"Manufacturing Dataset/test/SWaT_Dataset_Normal_v1.csv\", low_memory=False)#, nrows=1000)     normal = normal.drop([\"Timestamp\" , \"Normal/Attack\" ] , axis = 1)      # Transform all columns into float64     for i in list(normal):          normal[i]=normal[i].apply(lambda x: str(x).replace(\",\" , \".\"))     normal = normal.astype(float)          min_max_scaler = preprocessing.MinMaxScaler()     x = normal.values     x_scaled = min_max_scaler.fit_transform(x)     normal = pd.DataFrame(x_scaled)      attack = pd.read_csv(\"Manufacturing Dataset/test/SWaT_Dataset_Attack_v0.csv\",sep=\";\", low_memory=False)#, nrows=1000)     labels = [ float(label!= 'Normal' ) for label  in attack[\"Normal/Attack\"].values]     attack = attack.drop([\"Timestamp\" , \"Normal/Attack\" ] , axis = 1)          for i in list(attack):         attack[i]=attack[i].apply(lambda x: str(x).replace(\",\" , \".\"))     attack = attack.astype(float)     x = attack.values     x_scaled = min_max_scaler.fit_transform(x)     attack = pd.DataFrame(x_scaled)          windows_normal=normal.values[np.arange(window_size)[None, :] + np.arange(normal.shape[0]-window_size)[:, None]]     windows_attack=attack.values[np.arange(window_size)[None, :] + np.arange(attack.shape[0]-window_size)[:, None]]      windows_normal_train = windows_normal[:int(np.floor(.8 *  windows_normal.shape[0]))]     windows_normal_val = windows_normal[int(np.floor(.8 *  windows_normal.shape[0])):int(np.floor(windows_normal.shape[0]))]      return windows_normal_train, windows_normal_val, windows_attack, labels  windows_normal_train, windows_normal_val, windows_test, y_test = generate_dataset(CONFIG[\"Batch\"], CONFIG[\"Window\"])  w_size=windows_normal_train.shape[1] * windows_normal_train.shape[2] z_size=windows_normal_train.shape[1] * CONFIG[\"Hidden\"]  train_dataset = tf.data.Dataset.from_tensor_slices(     windows_normal_train.astype(np.float32).reshape([windows_normal_train.shape[0], w_size]) ).batch(CONFIG[\"Batch\"], drop_remainder=False)  val_dataset = tf.data.Dataset.from_tensor_slices(     windows_normal_val.astype(np.float32).reshape([windows_normal_val.shape[0], w_size]) ).batch(CONFIG[\"Batch\"], drop_remainder=False)  test_dataset = tf.data.Dataset.from_tensor_slices(     windows_test.astype(np.float32).reshape([windows_test.shape[0], w_size]) ).batch(CONFIG[\"Batch\"], drop_remainder=False)  windows_labels=[] for i in range(len(y_test) - CONFIG[\"Window\"]):     windows_labels.append(list(np.int_(y_test[i:i+CONFIG[\"Window\"]]))) y_test = [1.0 if (np.sum(window) &gt; 0) else 0 for window in windows_labels ]  model = USAD(w_size, z_size) optimizer1 = tf.optimizers.Adam(learning_rate = 0.001) optimizer2 = tf.optimizers.Adam(learning_rate = 0.001) for epoch in range(1, CONFIG[\"Epoch\"] + 1):     for step, batch in enumerate(train_dataset):                         with tf.GradientTape() as tape1, tf.GradientTape() as tape2:                 loss1,loss2 = model(batch, epoch, training = True)                 grads1 = tape1.gradient(loss1, model.encoder.trainable_variables + model.decoder1.trainable_variables)                 grads2 = tape2.gradient(loss2, model.encoder.trainable_variables + model.decoder2.trainable_variables)                 optimizer1.apply_gradients(zip(grads1, model.encoder.trainable_variables + model.decoder1.trainable_variables))                 optimizer2.apply_gradients(zip(grads2, model.encoder.trainable_variables + model.decoder2.trainable_variables))                      loss1_l, loss2_l = [], []     for step, batch in enumerate(val_dataset):         loss1, loss2 = model(batch, epoch, training = False)         loss1_l.append(loss1)         loss2_l.append(loss2)     loss1_avg = tf.reduce_mean(loss1_l)     loss2_avg = tf.reduce_mean(loss2_l)     print(\"Epoch [%d]\" % (epoch), 'val_loss1:', str(loss1_avg.numpy()) + ', val_loss2:', loss2_avg.numpy())    Reference:     https://github.com/manigalati/usad   https://dl.acm.org/doi/10.1145/3394486.3403392  ","categories": ["Deep Learning"],
        "tags": ["Anomaly Detection"],
        "url": "/deeplearning/usad",
        "teaser": null
      },{
        "title": "[YOLOv3] An Incremental Improvement",
        "excerpt":"Introduction   2015ë…„ì— ë°”ìš´ë”©ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ë¥¼ íšŒê·€ ë°©ì‹ìœ¼ë¡œ ê°ì²´ íƒì§€í•˜ëŠ” YOLO(You Only Look Once) ëª¨ë¸ì´ ì œì•ˆëë‹¤. 3ë…„ì´ ì§€ë‚œ í›„ UWì˜ Joseph Redmonê³¼ Ali FarhardiëŠ” YOLOë¥¼ ì—…ê·¸ë ˆì´ë“œí•´ì„œ YOLOv3ë¥¼ ë‹¤ì‹œ ì œì•ˆí–ˆë‹¤. YOLOv3ëŠ” end-to-endë¡œ í•™ìŠµë˜ëŠ” single-stage ëª¨ë¸ë¡œ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë‹¤ì–‘í•œ ê°ì²´ë“¤ì„ ë¹ ë¥´ê²Œ ê²€ì¶œí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ìœ ëª…í•˜ë‹¤. ë˜í•œ YOLOv3ì—ì„œëŠ” Darknet-53ì´ë¼ëŠ” ìƒˆë¡œìš´ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ê°€ ë„ì…ë˜ì–´ ì´ì „ ë²„ì „ë³´ë‹¤ ë” ë†’ì€ ì •í™•ë„ë¥¼ ì œê³ í•œë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œ ì…€ë¡œ ë‚˜ëˆ„ê³ , ê° ì…€ì´ íŠ¹ì • ê°œìˆ˜ì˜ bounding boxë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©ëœë‹¤. ê·¸ë¦¬ê³  ì˜ˆì¸¡ëœ bounding boxëŠ” í•´ë‹¹ ê°ì²´ì˜ í´ë˜ìŠ¤ì™€ confidence scoreë¥¼ ê°€ì§„ë‹¤.   Architecture        YOLO v3ëŠ” ì„œë¡œ ë‹¤ë¥¸ 3ê°œì˜ scaleì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•œë‹¤. ë¨¼ì € 416x416 í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë„£ì–´ì„œ í¬ê¸°ê°€ 52x52, 26x26, 13x13ì´ ë˜ëŠ” ë ˆì´ì–´ì—ì„œ íŠ¹ì§•ë§µì„ ì¶”ì¶œí•œë‹¤. ê·¸ ë‹¤ìŒ ê°€ì¥ ë†’ì€ ë‹¨ê³„ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§•ë§µì„ 1x1, 3x3 Conv ë ˆì´ì–´ë¡œ êµ¬ì„±ëœ ë„¤íŠ¸ì›Œí¬ì— ë„£ì–´ì£¼ê³ , Filterì˜ ê°œìˆ˜ê°€ 512ê°€ ë˜ëŠ” ì§€ì ì—ì„œ 2ë°°ë¡œ upsampling í•œ ë’¤, ë°”ë¡œ ì•„ë˜ ë‹¨ê³„ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§•ë§µê³¼ Concatenateí•´ì¤€ë‹¤. ì´ ê³¼ì •ì„ ê°€ì¥ ë°‘ ë‹¨ê³„ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§•ë§µì—ì„œë„ ì ìš©í•œë‹¤. ì´ë¥¼ í†µí•´ ì´ 3ê°œì˜ Scaleë¥¼ ê°€ì§„ ìƒˆë¡œìš´ íŠ¹ì§•ë§µì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  ì´ ë•Œ ê° Scaleì˜ íŠ¹ì§•ë§µì˜ ì±„ë„ ê°œìˆ˜ê°€ (255 = 3 x (4 + 1 + Num of Classes))ê°€ ë˜ë„ë¡ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤.   ì´ ë°©ë²•ì„ í†µí•´ ë” ë†’ì€ ë‹¨ê³„ì—ì„œì˜ íŠ¹ì§•ë§µìœ¼ë¡œ ë¶€í„° fine-grained ì •ë³´ë¥¼ ì–»ê³ , ë” ë‚®ì€ ë‹¨ê³„ì—ì„œì˜ íŠ¹ì§•ë§µìœ¼ë¡œë¶€í„° ë” ìœ ìš©í•œ semantic ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.   Feature Extractor     YOLO v3ì—ì„œëŠ” Darknet-53ì„ backbone ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. Darkenet-53ì€ ResNet-101ë³´ë‹¤ 1.5ë°° ë¹ ë¥´ê³ , ResNet-152ì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ 2ë°° ì´ìƒ ë¹ ë¥´ë‹¤.   Training Train YOLOv3  ì•ì„œ ì–»ì€ multi-scale feature mapsë¥¼ loss functionì„ í†µí•´ í•™ìŠµì‹œí‚¨ë‹¤.      bounding box offsetì˜ MSE(Mean Squared Error)   ê°ì²´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í• ë‹¹ëœ(responsible for) bounding boxì˜ objectness scoreì˜ BCE(Binary Cross Entropy)   ê°ì²´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í• ë‹¹ë˜ì§€ ì•Šì€ bounding boxì˜ no objectness scoreì˜ BCE   bounding boxì˜ multi-class BCE   ê·¸ë¦¬ê³  Inference ì‹œì—ëŠ” ë§ˆì§€ë§‰ ì˜ˆì¸¡ ê²°ê³¼ì— NMS(Non Maximum Suppression)ì„ ì ìš©í•œë‹¤.   Results     Reference:     https://arxiv.org/pdf/1804.02767.pdf   https://d33wubrfki0l68.cloudfront.net/c6fd049f28b66dbd35faed6965905ec6281f7d7d/c0399/assets/images/yolo/yolo-architecture.webp   https://towardsdatascience.com/dive-really-deep-into-yolo-v3-a-beginners-guide-9e3d2666280e    ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/yolov3",
        "teaser": null
      },{
        "title": "[Stable Diffusion] High-Resolution Image Synthesis with Latent Diffusion Models",
        "excerpt":" ","categories": ["Deep Learning"],
        "tags": ["Computer Vision"],
        "url": "/deeplearning/stablediffusion",
        "teaser": null
      }]
